{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "_A_4II-zq-9u",
      "metadata": {
        "id": "_A_4II-zq-9u"
      },
      "source": [
        "## Hardware information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7xGASvs3jrp-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xGASvs3jrp-",
        "outputId": "3ec96643-5e1c-44f0-988e-6660fe9078bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/cpuinfo | grep 'model name'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7RwXa9i7yvnq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RwXa9i7yvnq",
        "outputId": "6e8a088a-45ab-4052-c833-c08ce5f9e183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu cores\t: 1\n",
            "cpu cores\t: 1\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/cpuinfo | grep 'cpu cores'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mcq2-ZDQyhu6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mcq2-ZDQyhu6",
        "outputId": "0243620a-4836-4088-dafa-7501f1b546ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 1485.873\r\n",
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 3000.000\r\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/cpuinfo | grep 'cpu MHz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1SCMe2tzzKC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1SCMe2tzzKC",
        "outputId": "423794e2-6094-4b9e-9853-d17c43d5b4d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Architecture:                       x86_64\r\n"
          ]
        }
      ],
      "source": [
        "!lscpu | grep 'Architecture'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5pGWla8wz6uJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pGWla8wz6uJ",
        "outputId": "9e6834ea-73c4-4cb0-eed1-77ef22329633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thread(s) per core:                 2\r\n"
          ]
        }
      ],
      "source": [
        "!lscpu | grep 'Thread(s) per core'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cw0C0OiattgM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw0C0OiattgM",
        "outputId": "f3df414d-1b30-49cc-e7b5-83a16c0449c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Core(s) per socket:                 4\r\n"
          ]
        }
      ],
      "source": [
        "!lscpu | grep 'Core(s) per socket'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LFki5RGa0SER",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFki5RGa0SER",
        "outputId": "a965d32e-9f64-45a4-ffbc-ad8eae7325e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Socket(s):                          1\r\n"
          ]
        }
      ],
      "source": [
        "!lscpu | grep 'Socket(s)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b9x-fE0kuR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44b9x-fE0kuR",
        "outputId": "301fe943-a11e-4309-b07d-60c0fa77d633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MemTotal:       62745496 kB\r\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/meminfo | grep 'MemTotal'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ht1hzoWljsVf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht1hzoWljsVf",
        "outputId": "9eab50fd-e605-4037-8435-8044e21db8cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-b42ad1e9-bc98-7b0f-288a-a11837d8d0ff)\r\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0837de7",
      "metadata": {
        "id": "a0837de7"
      },
      "source": [
        "## Install requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "WfhbazC2G05s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfhbazC2G05s",
        "outputId": "a5fbf070-a981-4064-d0ae-42e4f2990bfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement upgrade (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for upgrade\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting accelerate@ git+https://github.com/huggingface/accelerate@97d2168e5953fe7373a06c69c02c5a00a84d5344 (from -r requirements.txt (line 2))\n",
            "  Cloning https://github.com/huggingface/accelerate (to revision 97d2168e5953fe7373a06c69c02c5a00a84d5344) to /tmp/pip-install-m6px5mte/accelerate_c76db6ab3d38400d9f0eff49d104170d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-install-m6px5mte/accelerate_c76db6ab3d38400d9f0eff49d104170d\n",
            "  Running command git rev-parse -q --verify 'sha^97d2168e5953fe7373a06c69c02c5a00a84d5344'\n",
            "  Running command git fetch -q https://github.com/huggingface/accelerate 97d2168e5953fe7373a06c69c02c5a00a84d5344\n",
            "  Running command git checkout -q 97d2168e5953fe7373a06c69c02c5a00a84d5344\n",
            "  Resolved https://github.com/huggingface/accelerate to commit 97d2168e5953fe7373a06c69c02c5a00a84d5344\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: absl-py==2.1.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: aiohttp==3.9.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (3.9.3)\n",
            "Requirement already satisfied: aiosignal==1.3.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: asttokens==2.4.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (2.4.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.6.3)\n",
            "Requirement already satisfied: async-timeout==4.0.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (4.0.3)\n",
            "Requirement already satisfied: attrs==23.2.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (23.2.0)\n",
            "Requirement already satisfied: backcall==0.2.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: cachetools==5.3.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (5.3.2)\n",
            "Requirement already satisfied: captum==0.7.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (2024.2.2)\n",
            "Requirement already satisfied: chardet==3.0.4 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (3.3.2)\n",
            "Requirement already satisfied: click==8.1.7 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (8.1.7)\n",
            "Requirement already satisfied: comm==0.2.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (0.2.1)\n",
            "Requirement already satisfied: contourpy==1.1.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (1.1.1)\n",
            "Requirement already satisfied: cycler==0.12.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 18)) (0.12.1)\n",
            "Requirement already satisfied: datasets==2.17.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 19)) (2.17.1)\n",
            "Requirement already satisfied: debugpy==1.8.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 20)) (1.8.1)\n",
            "Requirement already satisfied: decorator==5.1.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 21)) (5.1.1)\n",
            "Requirement already satisfied: dill==0.3.8 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 22)) (0.3.8)\n",
            "Requirement already satisfied: eli5==0.13.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 23)) (0.13.0)\n",
            "Requirement already satisfied: emoji==2.10.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 24)) (2.10.1)\n",
            "Requirement already satisfied: et-xmlfile==1.1.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 25)) (1.1.0)\n",
            "Requirement already satisfied: evaluate==0.4.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 26)) (0.4.1)\n",
            "Requirement already satisfied: executing==2.0.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 27)) (2.0.1)\n",
            "Requirement already satisfied: filelock==3.13.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 28)) (3.13.1)\n",
            "Requirement already satisfied: flatbuffers==23.5.26 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 29)) (23.5.26)\n",
            "Requirement already satisfied: fonttools==4.49.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 30)) (4.49.0)\n",
            "Requirement already satisfied: frozenlist==1.4.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 31)) (1.4.1)\n",
            "Requirement already satisfied: fsspec==2023.10.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 32)) (2023.10.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 33)) (0.4.0)\n",
            "Requirement already satisfied: google-auth==2.28.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 34)) (2.28.0)\n",
            "Requirement already satisfied: google-auth-oauthlib==1.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 35)) (1.0.0)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 36)) (0.2.0)\n",
            "Requirement already satisfied: googletrans==4.0.0rc1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 37)) (4.0.0rc1)\n",
            "Requirement already satisfied: graphviz==0.20.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 38)) (0.20.1)\n",
            "Requirement already satisfied: grpcio==1.60.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 39)) (1.60.1)\n",
            "Requirement already satisfied: h11==0.9.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 40)) (0.9.0)\n",
            "Requirement already satisfied: h2==3.2.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 41)) (3.2.0)\n",
            "Requirement already satisfied: h5py==3.10.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 42)) (3.10.0)\n",
            "Requirement already satisfied: hpack==3.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 43)) (3.0.0)\n",
            "Requirement already satisfied: hstspreload==2024.3.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 44)) (2024.3.1)\n",
            "Requirement already satisfied: httpcore==0.9.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 45)) (0.9.1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 46)) (0.13.3)\n",
            "Requirement already satisfied: huggingface-hub==0.20.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 47)) (0.20.3)\n",
            "Requirement already satisfied: hyperframe==5.2.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 48)) (5.2.0)\n",
            "Requirement already satisfied: idna==2.10 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 49)) (2.10)\n",
            "Requirement already satisfied: importlib-metadata==7.0.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 50)) (7.0.1)\n",
            "Requirement already satisfied: importlib-resources==6.1.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 51)) (6.1.1)\n",
            "Requirement already satisfied: ipykernel==6.29.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 52)) (6.29.2)\n",
            "Collecting ipython==8.10.0 (from -r requirements.txt (line 53))\n",
            "  Downloading ipython-8.10.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jedi==0.19.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 54)) (0.19.1)\n",
            "Requirement already satisfied: Jinja2==3.1.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 55)) (3.1.3)\n",
            "Requirement already satisfied: joblib==1.3.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 56)) (1.3.2)\n",
            "Requirement already satisfied: jupyter_client==8.6.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 57)) (8.6.0)\n",
            "Requirement already satisfied: jupyter_core==5.7.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 58)) (5.7.1)\n",
            "Requirement already satisfied: keras==2.13.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 59)) (2.13.1)\n",
            "Requirement already satisfied: kiwisolver==1.4.5 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 60)) (1.4.5)\n",
            "Requirement already satisfied: libclang==16.0.6 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 61)) (16.0.6)\n",
            "Requirement already satisfied: Markdown==3.5.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 62)) (3.5.2)\n",
            "Requirement already satisfied: MarkupSafe==2.1.5 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 63)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib==3.7.5 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 64)) (3.7.5)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 65)) (0.1.6)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 66)) (1.3.0)\n",
            "Requirement already satisfied: multidict==6.0.5 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 67)) (6.0.5)\n",
            "Requirement already satisfied: multiprocess==0.70.16 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 68)) (0.70.16)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 69)) (1.6.0)\n",
            "Requirement already satisfied: networkx==3.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 70)) (3.1)\n",
            "Requirement already satisfied: nltk==3.8.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 71)) (3.8.1)\n",
            "Requirement already satisfied: numpy==1.24.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 72)) (1.24.3)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 73)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 74)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 75)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 76)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 77)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 78)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 79)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 80)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 81)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 82)) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.3.101 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 83)) (12.3.101)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 84)) (12.1.105)\n",
            "Requirement already satisfied: oauthlib==3.2.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 85)) (3.2.2)\n",
            "Requirement already satisfied: openpyxl==3.1.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 86)) (3.1.2)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 87)) (3.3.0)\n",
            "Requirement already satisfied: packaging==23.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 88)) (23.2)\n",
            "Requirement already satisfied: pandas==2.0.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 89)) (2.0.3)\n",
            "Requirement already satisfied: parso==0.8.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 90)) (0.8.3)\n",
            "Requirement already satisfied: pexpect==4.9.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 91)) (4.9.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 92)) (0.7.5)\n",
            "Requirement already satisfied: pillow==10.2.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 93)) (10.2.0)\n",
            "Requirement already satisfied: platformdirs==4.2.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 94)) (4.2.0)\n",
            "Requirement already satisfied: preprocessor==1.1.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 95)) (1.1.3)\n",
            "Requirement already satisfied: prompt-toolkit==3.0.43 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 96)) (3.0.43)\n",
            "Requirement already satisfied: protobuf==4.25.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 97)) (4.25.3)\n",
            "Requirement already satisfied: psutil==5.9.8 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 98)) (5.9.8)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 99)) (0.7.0)\n",
            "Requirement already satisfied: pure-eval==0.2.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 100)) (0.2.2)\n",
            "Requirement already satisfied: pyarrow==15.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 101)) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix==0.6 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 102)) (0.6)\n",
            "Requirement already satisfied: pyasn1==0.5.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 103)) (0.5.1)\n",
            "Requirement already satisfied: pyasn1-modules==0.3.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 104)) (0.3.0)\n",
            "Requirement already satisfied: Pygments==2.17.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 105)) (2.17.2)\n",
            "Requirement already satisfied: pyparsing==3.1.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 106)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 107)) (2.8.2)\n",
            "Requirement already satisfied: pytz==2024.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 108)) (2024.1)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 109)) (6.0.1)\n",
            "Requirement already satisfied: pyzmq==25.1.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 110)) (25.1.2)\n",
            "Requirement already satisfied: regex==2023.12.25 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 111)) (2023.12.25)\n",
            "Requirement already satisfied: requests==2.31.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 112)) (2.31.0)\n",
            "Requirement already satisfied: requests-oauthlib==1.3.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 113)) (1.3.1)\n",
            "Requirement already satisfied: responses==0.18.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 114)) (0.18.0)\n",
            "Requirement already satisfied: rfc3986==1.5.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 115)) (1.5.0)\n",
            "Requirement already satisfied: rsa==4.9 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 116)) (4.9)\n",
            "Requirement already satisfied: safetensors==0.4.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 117)) (0.4.2)\n",
            "Requirement already satisfied: scikit-learn==1.3.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 118)) (1.3.2)\n",
            "Requirement already satisfied: scipy==1.10.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 119)) (1.10.1)\n",
            "Requirement already satisfied: seaborn==0.13.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 120)) (0.13.2)\n",
            "Requirement already satisfied: sentence-transformers==2.3.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 121)) (2.3.1)\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 122)) (0.2.0)\n",
            "Requirement already satisfied: six==1.16.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 123)) (1.16.0)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 124)) (1.3.1)\n",
            "Requirement already satisfied: stack-data==0.6.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 125)) (0.6.3)\n",
            "Requirement already satisfied: sympy==1.12 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 126)) (1.12)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 127)) (0.9.0)\n",
            "Requirement already satisfied: tensorboard==2.13.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 128)) (2.13.0)\n",
            "Requirement already satisfied: tensorboard-data-server==0.7.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 129)) (0.7.2)\n",
            "Requirement already satisfied: tensorflow==2.13.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 130)) (2.13.1)\n",
            "Requirement already satisfied: tensorflow-estimator==2.13.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 131)) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.34.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 132)) (0.34.0)\n",
            "Requirement already satisfied: termcolor==2.4.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 133)) (2.4.0)\n",
            "Requirement already satisfied: threadpoolctl==3.3.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 134)) (3.3.0)\n",
            "Requirement already satisfied: tokenizers==0.15.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 135)) (0.15.2)\n",
            "Requirement already satisfied: torch==2.1.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 136)) (2.1.2)\n",
            "Requirement already satisfied: tornado==6.4 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 137)) (6.4)\n",
            "Requirement already satisfied: tqdm==4.66.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 138)) (4.66.2)\n",
            "Requirement already satisfied: traitlets==5.14.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 139)) (5.14.1)\n",
            "Requirement already satisfied: transformers==4.38.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 140)) (4.38.0)\n",
            "Requirement already satisfied: transformers-interpret==0.10.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 141)) (0.10.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 142)) (2.1.0)\n",
            "Requirement already satisfied: typing_extensions==4.5.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 143)) (4.5.0)\n",
            "Requirement already satisfied: tzdata==2024.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 144)) (2024.1)\n",
            "Requirement already satisfied: urllib3==2.2.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 145)) (2.2.1)\n",
            "Requirement already satisfied: wcwidth==0.2.13 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 146)) (0.2.13)\n",
            "Requirement already satisfied: Werkzeug==3.0.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 147)) (3.0.1)\n",
            "Requirement already satisfied: wrapt==1.16.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 148)) (1.16.0)\n",
            "Requirement already satisfied: xxhash==3.4.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 149)) (3.4.1)\n",
            "Requirement already satisfied: yarl==1.9.4 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 150)) (1.9.4)\n",
            "Requirement already satisfied: zipp==3.17.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 151)) (3.17.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from astunparse==1.6.3->-r requirements.txt (line 6)) (0.42.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorboard==2.13.0->-r requirements.txt (line 128)) (69.1.0)\n",
            "INFO: pip is looking at multiple versions of transformers-interpret to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ipykernel==6.29.2 (from -r requirements.txt (line 52))\n",
            "  Using cached ipykernel-6.29.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "\u001b[31mERROR: Cannot install -r requirements.txt (line 52), ipython==8.10.0 and transformers-interpret==0.10.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested ipython==8.10.0\n",
            "    ipykernel 6.29.2 depends on ipython>=7.23.1\n",
            "    transformers-interpret 0.10.0 depends on ipython<8.0.0 and >=7.31.1\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: emoji in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (2.10.1)\n",
            "Requirement already satisfied: preprocessor in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (1.1.3)\n",
            "Requirement already satisfied: sentence_transformers in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (2.3.1)\n",
            "Requirement already satisfied: eli5 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (0.13.0)\n",
            "Requirement already satisfied: captum in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (0.7.0)\n",
            "Requirement already satisfied: transformers_interpret in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (0.10.0)\n",
            "Requirement already satisfied: evaluate in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (0.4.1)\n",
            "Requirement already satisfied: tensorflow in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (2.13.1)\n",
            "Requirement already satisfied: transformers[torch] in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (4.38.0)\n",
            "Requirement already satisfied: tqdm in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from sentence_transformers) (2.1.2)\n",
            "Requirement already satisfied: numpy in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: scikit-learn in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from sentence_transformers) (0.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from sentence_transformers) (10.2.0)\n",
            "Requirement already satisfied: attrs>17.1.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from eli5) (23.2.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from eli5) (3.1.3)\n",
            "Requirement already satisfied: six in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from eli5) (1.16.0)\n",
            "Requirement already satisfied: graphviz in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from eli5) (0.20.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from eli5) (0.9.0)\n",
            "Requirement already satisfied: matplotlib in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from captum) (3.7.5)\n",
            "Requirement already satisfied: ipython<8.0.0,>=7.31.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from transformers_interpret) (7.34.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from evaluate) (2.17.1)\n",
            "Requirement already satisfied: dill in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
            "Requirement already satisfied: packaging in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from evaluate) (23.2)\n",
            "Requirement already satisfied: responses<0.19 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: filelock in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from transformers[torch]) (0.28.0.dev0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (1.60.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (4.25.3)\n",
            "Requirement already satisfied: setuptools in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (69.1.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: psutil in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (0.19.1)\n",
            "Requirement already satisfied: decorator in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (5.14.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (3.0.43)\n",
            "Requirement already satisfied: pygments in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (2.17.2)\n",
            "Requirement already satisfied: backcall in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from jinja2>=3.0.0->eli5) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from scikit-learn->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: sympy in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.3.101)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from matplotlib->captum) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from matplotlib->captum) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from matplotlib->captum) (6.1.1)\n",
            "Requirement already satisfied: click in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->captum) (3.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from jedi>=0.16->ipython<8.0.0,>=7.31.1->transformers_interpret) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (7.0.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from pexpect>4.3->ipython<8.0.0,>=7.31.1->transformers_interpret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0.0,>=7.31.1->transformers_interpret) (0.2.13)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
            "Collecting git+https://github.com/huggingface/accelerate\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-5kb7gl4w\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-5kb7gl4w\n",
            "  Resolved https://github.com/huggingface/accelerate to commit 156331aecd977d3961ef8a8e01c9c2feaf38ed60\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from accelerate==0.30.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from accelerate==0.30.0.dev0) (23.2)\n",
            "Requirement already satisfied: psutil in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from accelerate==0.30.0.dev0) (5.9.8)\n",
            "Requirement already satisfied: pyyaml in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from accelerate==0.30.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from accelerate==0.30.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: huggingface-hub in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from accelerate==0.30.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from accelerate==0.30.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: filelock in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.30.0.dev0) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.30.0.dev0) (12.3.101)\n",
            "Requirement already satisfied: requests in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from huggingface-hub->accelerate==0.30.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from huggingface-hub->accelerate==0.30.0.dev0) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate==0.30.0.dev0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate==0.30.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate==0.30.0.dev0) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate==0.30.0.dev0) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate==0.30.0.dev0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/leonides/.venv/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate==0.30.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: accelerate\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.30.0.dev0-py3-none-any.whl size=300147 sha256=ce6c98c5ac2bc96938f74a09286dbdc8d5bac538f9f12d5fd3f78ea557d0e09e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uf0tle77/wheels/3f/89/7d/47b6949afa88c1fcde5a743260609e1bc080b2d24739caa6cd\n",
            "Successfully built accelerate\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.28.0.dev0\n",
            "    Uninstalling accelerate-0.28.0.dev0:\n",
            "      Successfully uninstalled accelerate-0.28.0.dev0\n",
            "Successfully installed accelerate-0.30.0.dev0\n",
            "/bin/bash: -c: line 0: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 0: `pip install() --upgrade transformers'\n"
          ]
        }
      ],
      "source": [
        "!pip install upgrade tensorflow\n",
        "!pip install -r requirements.txt\n",
        "!pip install emoji preprocessor sentence_transformers eli5 captum transformers_interpret evaluate transformers[torch] tensorflow\n",
        "!pip install git+https://github.com/huggingface/accelerate\n",
        "!pip install() --upgrade transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mw0oazPkrgOJ",
      "metadata": {
        "id": "Mw0oazPkrgOJ"
      },
      "source": [
        "# Imports and function definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "P8gGrvdODJvN",
      "metadata": {
        "id": "P8gGrvdODJvN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-29 14:39:53.998045: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-04-29 14:39:55.233299: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-29 14:39:57.183055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# General purpose\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Modeling\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.set_flush_denormal(True)\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    AdamW,\n",
        "    BertTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Hugging Face Dataset\n",
        "from datasets import Dataset\n",
        "\n",
        "# Model performance evaluation\n",
        "import evaluate\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    confusion_matrix\n",
        ")\n",
        "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ignore warnings\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# Others\n",
        "import os\n",
        "from sklearn.utils import check_random_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d02SkCGgDfV7",
      "metadata": {
        "id": "d02SkCGgDfV7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "# Create a set of stop words\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "95d7e776",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95d7e776",
        "outputId": "ff7f0cb8-411e-44e6-a36f-354aae7bdce3"
      },
      "outputs": [],
      "source": [
        "class BertClassifier:\n",
        "    \"\"\"\n",
        "    BERT-based text classifier for sequence classification tasks.\n",
        "\n",
        "    This class provides functionality to train, evaluate, and use a BERT\n",
        "    model for text classification tasks. It encapsulates the BERT model\n",
        "    initialization, tokenization, training, evaluation, and prediction\n",
        "    processes.\n",
        "\n",
        "    Methods:\n",
        "        __compute_metrics: Computes evaluation metrics.\n",
        "        compute_loss: Computes the loss using Cross Entropy Loss.\n",
        "        fit: Fine-tune the BERT model using the provided training data.\n",
        "        predict: Make predictions on input text data using the trained model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, training_args, id2label):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - training_args (TrainingArguments): Training arguments for\n",
        "          fine-tuning BERT.\n",
        "        - id2label (dict): Dictionary mapping label IDs to their corresponding\n",
        "          labels.\n",
        "        \"\"\"\n",
        "        self.model = BertForSequenceClassification.from_pretrained(\n",
        "            'bert-base-uncased',\n",
        "            num_labels=17,\n",
        "            id2label=id2label\n",
        "        )\n",
        "        self.device = torch.device(\n",
        "            'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        )\n",
        "        self.model.to(self.device)\n",
        "        self.optimizer = AdamW(self.model.parameters(), lr=2e-5)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.training_args = training_args\n",
        "        self.trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=self.training_args,\n",
        "            train_dataset=None,\n",
        "            eval_dataset=None,\n",
        "            compute_metrics=None\n",
        "        )\n",
        "\n",
        "    def __compute_metrics(self, eval_pred):\n",
        "        \"\"\"\n",
        "        Computes evaluation metrics.\n",
        "\n",
        "        This method computes evaluation metrics such as accuracy, precision,\n",
        "        recall, and F1-score based on the provided logits and labels.\n",
        "\n",
        "        Parameters:\n",
        "        - eval_pred (tuple): A tuple containing logits and labels.\n",
        "\n",
        "        Return:\n",
        "            dict: A dictionary containing the evaluation metrics including:\n",
        "                - 'accuracy': Accuracy score\n",
        "                - 'precision': Precision score (macro average)\n",
        "                - 'recall': Recall score (macro average)\n",
        "                - 'f1': F1 score (macro average)\n",
        "        \"\"\"\n",
        "        logits, labels = eval_pred\n",
        "        # probabilities = tf.nn.softmax(logits)\n",
        "        predictions = np.argmax(logits, axis=1)\n",
        "        results = {\n",
        "            'accuracy': accuracy_score(labels, predictions),\n",
        "            'precision': precision_score(\n",
        "                labels,\n",
        "                predictions,\n",
        "                average='macro',\n",
        "                zero_division=0\n",
        "            ),\n",
        "            'recall': recall_score(\n",
        "                labels,\n",
        "                predictions,\n",
        "                average='macro',\n",
        "                zero_division=0\n",
        "            ),\n",
        "            'f1': f1_score(\n",
        "                labels,\n",
        "                predictions,\n",
        "                average='macro',\n",
        "                zero_division=0\n",
        "            )\n",
        "        }\n",
        "        return results\n",
        "\n",
        "    def compute_loss(self, eval_pred):\n",
        "        \"\"\"\n",
        "        Computes the loss using Cross Entropy Loss.\n",
        "\n",
        "        This method calculates the loss using the Cross Entropy Loss function\n",
        "        based on the provided logits and labels.\n",
        "\n",
        "        Parameters:\n",
        "        - eval_pred (tuple): A tuple containing logits and labels.\n",
        "\n",
        "        Return:\n",
        "            torch.Tensor: The computed loss value.\n",
        "        \"\"\"\n",
        "        logits, labels = eval_pred\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        loss = loss_fn(logits, labels)\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X_train, y_train, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Fine-tunes the BERT model using the provided training data.\n",
        "\n",
        "        This method fine-tunes the BERT model using the provided training data\n",
        "        and evaluates its performance on the provided testing data.\n",
        "\n",
        "        Parameters:\n",
        "        - X_train (list): A list of input text data for training.\n",
        "        - y_train (list): A list of corresponding labels for training.\n",
        "        - X_test (list): A list of input text data for testing.\n",
        "        - y_test (list): A list of corresponding labels for testing.\n",
        "        \"\"\"\n",
        "        train_tokens = self.tokenizer(\n",
        "            X_train,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            return_tensors='pt'\n",
        "        ).to(self.device)\n",
        "        train_tokens['labels'] = torch.tensor(y_train).to(self.device)\n",
        "        train_dataset = Dataset.from_dict(\n",
        "            {k: v for k, v in train_tokens.items()}\n",
        "        )\n",
        "\n",
        "        test_tokens = self.tokenizer(\n",
        "            X_test,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        test_tokens.to(self.device)\n",
        "        test_tokens['labels'] = torch.tensor(y_test).to(self.device)\n",
        "        test_dataset = Dataset.from_dict(\n",
        "            {k: v for k, v in test_tokens.items()}\n",
        "        )\n",
        "\n",
        "        self.trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=self.training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=test_dataset,\n",
        "            compute_metrics=self.__compute_metrics\n",
        "        )\n",
        "        self.trainer.train()\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Makes predictions on input text data using the trained model.\n",
        "\n",
        "        This method takes input text data, tokenizes it, and makes predictions\n",
        "        using the trained BERT model.\n",
        "\n",
        "        Parameters:\n",
        "        - X (list): A list of input text data.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: An array of predicted labels.\n",
        "        \"\"\"\n",
        "        test_tokens = self.tokenizer(\n",
        "            X,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        test_tokens.to(self.device)\n",
        "        test_dataset = Dataset.from_dict(\n",
        "            {k: v for k, v in test_tokens.items()}\n",
        "        )\n",
        "        self.trainer.compute_metrics = self.__compute_metrics\n",
        "        self.trainer.eval_dataset = test_dataset\n",
        "\n",
        "        predictions = self.trainer.predict(test_dataset)\n",
        "        return predictions.predictions\n",
        "\n",
        "def plot_confusion_matrix(\n",
        "    true_labels,\n",
        "    pred_labels,\n",
        "    figsize=(20, 10),\n",
        "    save=False,\n",
        "    save_path=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - true_labels: Actual labels\n",
        "    - pred_labels: Predicted labels\n",
        "    - figsize: Size of the figure (default is (15, 10))\n",
        "    \"\"\"\n",
        "    # Get unique labels\n",
        "    labels = np.unique(true_labels)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    # Convert to DataFrame for easier visualization\n",
        "    cm_df = pd.DataFrame(cm, index=labels + 1, columns=labels + 1)\n",
        "\n",
        "    # Create a heatmap using seaborn\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "\n",
        "    # Save the plot if save is True\n",
        "    if save:\n",
        "        plt.savefig(save_path)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def plot_classification_report(\n",
        "    df_report,\n",
        "    train_data,\n",
        "    figsize=(15, 10),\n",
        "    save=False,\n",
        "    save_path=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots a classification report.\n",
        "\n",
        "    Parameters:\n",
        "    - df_report: DataFrame containing the classification report\n",
        "    - train_data: DataFrame containing the training data\n",
        "    - figsize: Size of the figure (default is (15, 10))\n",
        "    \"\"\"\n",
        "    # Calculate the frequencies\n",
        "    frequencies = train_data['label'].value_counts()\n",
        "\n",
        "    # Create the xticks labels with frequencies\n",
        "    xticks = (\n",
        "        [\n",
        "            f'{label+1} ({frequencies[label]})'\n",
        "            for label in range(0, 17)\n",
        "        ]\n",
        "        + ['macro avg', 'weighted avg']\n",
        "    )\n",
        "\n",
        "    df_report.index = df_report.index.astype(str)\n",
        "\n",
        "    # Plot the classification report\n",
        "    df_report.plot(\n",
        "        kind='bar',\n",
        "        ylim=(0,1),\n",
        "        rot=90,\n",
        "        title='Classification Report',\n",
        "        figsize=figsize\n",
        "    )\n",
        "\n",
        "    # Set the xticks\n",
        "    _ = plt.xticks(range(len(xticks)-1), xticks)\n",
        "\n",
        "    # Save the plot if save is True\n",
        "    if save:\n",
        "        plt.savefig(save_path)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"\n",
        "    Computes the softmax function for an input array.\n",
        "\n",
        "    Parameters:\n",
        "    - x (numpy.ndarray): Input array of real numbers.\n",
        "\n",
        "    Return:\n",
        "        numpy.ndarray: An array of softmax probabilities corresponding to\n",
        "        each element in the input array 'x'.\n",
        "    \"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "def set_training_args():\n",
        "    \"\"\"\n",
        "    Generates training arguments and label mappings for a BERT-based sequence classification model.\n",
        "\n",
        "    Return:\n",
        "        tuple: A tuple containing two elements:\n",
        "            - training_args (TrainingArguments): Training arguments for the\n",
        "              Trainer object.\n",
        "            - id2label (dict): Dictionary mapping label indices to Sustainable\n",
        "              Development Goals (SDGs).\n",
        "    \"\"\"\n",
        "    # Set up model parameters\n",
        "    # Define the 17 SDGs\n",
        "    sdgs = [\n",
        "        'No Poverty',\n",
        "        'Zero Hunger',\n",
        "        'Good Health and Well-being',\n",
        "        'Quality Education',\n",
        "        'Gender Equality',\n",
        "        'Clean Water and Sanitation',\n",
        "        'Affordable and Clean Energy',\n",
        "        'Decent Work and Economic Growth',\n",
        "        'Industry, Innovation, and Infrastructure',\n",
        "        'Reduced Inequality',\n",
        "        'Sustainable Cities and Communities',\n",
        "        'Responsible Consumption and Production',\n",
        "        'Climate Action',\n",
        "        'Life Below Water',\n",
        "        'Life on Land',\n",
        "        'Peace, Justice, and Strong Institutions',\n",
        "        'Partnerships for the Goals'\n",
        "    ]\n",
        "\n",
        "    # Create a dictionary to map the SDGs to their respective IDs\n",
        "    id2label = {}\n",
        "\n",
        "    for i, sgd in enumerate(sdgs):\n",
        "        id2label[i] = sgd\n",
        "\n",
        "    # Set up the training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=(\n",
        "            './training_logs/bert-base-uncased-stratified-simplified/'\n",
        "        ),\n",
        "        logging_dir=(\n",
        "            './training_logs/bert-base-uncased-stratified-simplified/logs/'\n",
        "        ),\n",
        "        logging_strategy='epoch',\n",
        "        logging_steps=100,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        learning_rate=5e-6,\n",
        "        save_strategy='epoch',\n",
        "        save_steps=100,\n",
        "        evaluation_strategy='epoch',\n",
        "        eval_steps=100,\n",
        "        load_best_model_at_end=True,\n",
        "        num_train_epochs=10,\n",
        "    )\n",
        "\n",
        "    return training_args, id2label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b55cde2",
      "metadata": {
        "id": "5b55cde2"
      },
      "source": [
        "# **Model training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "51d57e48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "51d57e48",
        "outputId": "803ead36-daf6-4d4b-d32c-febb54462026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (13789, 2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>processed_abstract_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>manuscript report facile synthesis route elect...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cystoseira sargassaceae genus marine brown alg...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>colorectal cancer one common types cancer acco...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aims cardiac arrhythmias one important remote ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hesperidin abundant flavanone cheap byproduct ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             processed_abstract_text  label\n",
              "0  manuscript report facile synthesis route elect...      6\n",
              "1  cystoseira sargassaceae genus marine brown alg...      2\n",
              "2  colorectal cancer one common types cancer acco...      2\n",
              "3  aims cardiac arrhythmias one important remote ...      2\n",
              "4  hesperidin abundant flavanone cheap byproduct ...      2"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Meaning of columns:\n",
        "\n",
        "original_absract_text: The unprocessed abstract text\n",
        "preprocessed_abstract_text: The preprocessed abstract text\n",
        "tokens: The tokenized abstract text after preprocessing\n",
        "label_count: The number of labels\n",
        "label: The SDG label\n",
        "character_count: The number of characters in the unprocessed abstract text\n",
        "word_count: The number of words in the unprocessed abstract text\n",
        "token_count: The number of tokens in the tokenized abstract text\n",
        "\"\"\"\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('original_and_preprocessed.csv', \n",
        "                sep=';', encoding='utf-8', \n",
        "                usecols=['processed_abstract_text', 'label'] # Load only the necessary columns\n",
        "                )\n",
        "df['label'] = df['label'] - 1 # Adjust labels to start from 0 to 16 because the model expects labels from 0 to 16\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "print('Data shape:', df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bbb794e",
      "metadata": {
        "id": "4bbb794e"
      },
      "source": [
        "## **30x train-test run**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8cfba55",
      "metadata": {
        "id": "e8cfba55",
        "outputId": "331021ab-428b-43ee-a093-56c85ca67f86",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "Run:   0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are the counts equal? True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1637' max='27580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1637/27580 03:36 < 57:23, 7.53 it/s, Epoch 0.59/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 30x train-test run\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Initialize training arguments and label mappings\n",
        "training_args, id2label = set_training_args()\n",
        "\n",
        "# Load data resetting the index\n",
        "X = df['processed_abstract_text'].reset_index(drop=True)\n",
        "y = df['label'].reset_index(drop=True)\n",
        "\n",
        "total_cm = np.zeros((17, 17)) # Will be use to construct a confusion matrix composed of the means of the confusion matrices of each run\n",
        "classification_reports = [] # List to store the classification reports of each run to create a final report with the mean\n",
        "unique_labels = np.unique(y) # Get the unique classes in the entire dataset, will be needed to check if all labels are represented in both training and testing sets\n",
        "\n",
        "equal_counts_list = [] # To check if the\n",
        "\n",
        "# This code implements a small checkpoint system to avoid losing progress in case of an error\n",
        "# It will save the results of each run in a separate file, and the iteration number in a checkpoint file\n",
        "if os.path.exists('checkpoints/checkpoint.txt'): # Check if the checkpoint file exists\n",
        "    with open('checkpoints/checkpoint.txt', 'r') as f: # If it does, read the iteration number from it\n",
        "        start_iter = int(f.read())\n",
        "else:\n",
        "    start_iter = 0 # If it doesn't, start from 0\n",
        "\n",
        "# This for loop will run the model 30 times, each time with a different random state\n",
        "for i in tqdm(range(start_iter, 30), desc='Run', leave=True):\n",
        "    train_index, test_index = 0, 0 # initialize indices\n",
        "    X_train, X_test, y_train, y_test = np.array([]), np.array([]), np.array([]), np.array([]) # initiallize empty numpy arrays\n",
        "\n",
        "    try:\n",
        "        # Check if the report for this iteration already exists\n",
        "        if os.path.exists(f'checkpoints/report_{i}.csv'):\n",
        "            continue # If it does, skip this iteration\n",
        "\n",
        "        report_df = pd.DataFrame() # Initialize the report DataFrame\n",
        "\n",
        "        # Stratified shuffled train-test-split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i, stratify=y, shuffle=True)\n",
        "\n",
        "        # Get unique labels in y_test and y\n",
        "        unique_test_labels = np.unique(y_test)\n",
        "\n",
        "        # Because this is an unbalanced data set there might be some train-test-split where not all labels will be represented in both sets\n",
        "        # The next few lines will make sure at least 1 sample from each label is represented in the test set\n",
        "\n",
        "        if set(unique_test_labels) != set(unique_labels): # Check if not all labels are represented in the test set\n",
        "            missing_labels = set(unique_labels) - set(unique_test_labels) # Get the missing labels\n",
        "\n",
        "            # For each missing label, add samples from the training set to the test set\n",
        "            for missing_label in missing_labels:\n",
        "\n",
        "                # Collect the indices of the samples to be moved\n",
        "                missing_label_indices = y_train[y_train == missing_label].index.tolist()\n",
        "                # Get the index of the first occurence of the missing label\n",
        "                missing_label_index = missing_label_indices[0]\n",
        "\n",
        "                # Add these samples to the test set\n",
        "                X_test = pd.concat([X_test, X_train.loc[[missing_label_index]]], axis=0)\n",
        "                y_test = pd.concat([y_test, y_train.loc[[missing_label_index]]], axis=0)\n",
        "\n",
        "                # Remove these samples from the training set\n",
        "                X_train = X_train.drop(missing_label_index)\n",
        "                y_train = y_train.drop(missing_label_index)\n",
        "\n",
        "        # Initialize and fit the model\n",
        "        bert_classifier = BertClassifier(training_args, id2label)\n",
        "        bert_classifier.fit(X_train.tolist(), # The train and test sets need to be converted to lists\n",
        "                            y_train.tolist(),\n",
        "                            X_test.tolist(), # The test dataset is for evaluation only, the model will never see this set when training\n",
        "                            y_test.tolist()\n",
        "                            )\n",
        "\n",
        "        # Make predictions\n",
        "        pred_logits = bert_classifier.predict(X_test.tolist())\n",
        "        y_pred = np.argmax(pred_logits, axis=1) # Get the predicted labels from logits\n",
        "\n",
        "        # Get the classification report\n",
        "        report_dict = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "        # Convert the report to a DataFrame\n",
        "        report_df = pd.DataFrame(report_dict)\n",
        "        # Append the report to the list of reports, so later on we can calculate the mean and create a final report\n",
        "        classification_reports.append(report_df)\n",
        "\n",
        "        # Update the total confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
        "        total_cm += cm\n",
        "\n",
        "        # Used by the checkpoint system\n",
        "        # Save the results after each run\n",
        "\n",
        "        # Check if the necessary folders are present, if they aren't create them\n",
        "        if not os.path.exists('checkpoints'):\n",
        "            os.makedirs('checkpoints')\n",
        "        if not os.path.exists('results'):\n",
        "            os.makedirs('results')\n",
        "        if not os.path.exists('model'):\n",
        "            os.makedirs('model')\n",
        "\n",
        "        with open(f'checkpoints/report_{i}.csv', 'w') as f: # Save the current classification report\n",
        "            print(f'Saving report {i}...')\n",
        "            report_df.to_csv(f, sep=';', index_label='Metrics')\n",
        "        with open(f'checkpoints/total_cm_{i}.csv', 'w') as f: # Save the current confusion matrix\n",
        "            print(f'Saving confusion matrix {i}...')\n",
        "            pd.DataFrame(total_cm).to_csv(f, sep=';', index=False)\n",
        "        with open(f'results/pred_logits_{i}.csv', 'w') as f: # Save the prediction logits\n",
        "            print(f'Saving prediction logits {i}...')\n",
        "            pd.DataFrame(pred_logits).to_csv(f, sep=';', index=False)\n",
        "        # Save the current model weights so we can select the model weights with\n",
        "        # the best performance at the end of the experimetn\n",
        "        with open(f'model/model_state_{i}.pt', 'wb') as f:\n",
        "            print(f'Saving model state {i}...')\n",
        "            torch.save(bert_classifier.model.state_dict(), f)\n",
        "        # Save the current iteration number to the checkpoint file\n",
        "        with open('checkpoints/checkpoint.txt', 'w') as f:\n",
        "            print(f'Saving checkpoint {i}...')\n",
        "            f.write(str(i))\n",
        "\n",
        "    except Exception as e: # If an error occurs, print the error and the traceback\n",
        "        print(f'Error in run {i}: {e}')\n",
        "        traceback.print_exc()\n",
        "\n",
        "# This is the end of the 30x runs\n",
        "# Now, concatenate the reports and calculate the mean\n",
        "all_reports = pd.concat(classification_reports, axis=0)\n",
        "mean_reports = all_reports.groupby(all_reports.index).mean()\n",
        "\n",
        "# Save concatenated reports for backup\n",
        "with open('results/all_reports_backup.csv', 'w') as f:\n",
        "    print('Saving all reports...')\n",
        "    all_reports.to_csv(f, sep=';', index_label='Metrics')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c7f0da",
      "metadata": {
        "id": "b9c7f0da",
        "outputId": "8862c7e3-c705-421d-fd5e-b42c4cec3a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving all reports...\n"
          ]
        }
      ],
      "source": [
        "# Calculate the best run to get the best model_state\n",
        "\n",
        "_all_reports = all_reports\n",
        "\n",
        "# Calculate the number of metrics per run\n",
        "total_runs = 30\n",
        "metrics_per_run = len(_all_reports) // total_runs  # replace 'total_runs' with the actual number of runs\n",
        "\n",
        "# Create a range from 0 to the number of rows in _all_reports\n",
        "run_numbers = range(len(_all_reports))\n",
        "\n",
        "# Convert the range to a DataFrame\n",
        "run_numbers_df = pd.DataFrame(run_numbers, columns=['run_number'], index=_all_reports.index)\n",
        "\n",
        "# Divide the run numbers by the number of metrics per run and add 1 to get the run number for each report\n",
        "run_numbers_df['run_number'] = (run_numbers_df['run_number'] // metrics_per_run) + 1\n",
        "\n",
        "# Add the run number column to _all_reports\n",
        "_all_reports = pd.concat([_all_reports, run_numbers_df], axis=1)\n",
        "\n",
        "# Remove the 'support' rows\n",
        "_all_reports = _all_reports.drop('support')\n",
        "\n",
        "# Rename index to metrics\n",
        "_all_reports.index.name = 'metric'\n",
        "\n",
        "# Reset the index to move 'metric' from index to a regular column\n",
        "_all_reports.reset_index(inplace=True)\n",
        "\n",
        "# Get the best run number\n",
        "best_run_number = _all_reports['macro avg'].idxmax()\n",
        "\n",
        "# Save all reports\n",
        "with open('results/all_reports.csv', 'w') as f:\n",
        "    print('Saving all reports...')\n",
        "    _all_reports.to_csv(f, sep=';', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa0ba822",
      "metadata": {
        "id": "aa0ba822",
        "outputId": "62635320-ff80-4f9c-c2e2-328759d9558d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6087</td>\n",
              "      <td>0.9630</td>\n",
              "      <td>0.641415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.787927</td>\n",
              "      <td>0.889917</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.713996</td>\n",
              "      <td>0.442198</td>\n",
              "      <td>0.618922</td>\n",
              "      <td>0.162129</td>\n",
              "      <td>0.451739</td>\n",
              "      <td>0.757418</td>\n",
              "      <td>0.691908</td>\n",
              "      <td>0.346912</td>\n",
              "      <td>0.838568</td>\n",
              "      <td>0.886094</td>\n",
              "      <td>0.524398</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6057</td>\n",
              "      <td>0.9580</td>\n",
              "      <td>0.650871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.765447</td>\n",
              "      <td>0.872560</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.702552</td>\n",
              "      <td>0.757897</td>\n",
              "      <td>0.669004</td>\n",
              "      <td>0.337308</td>\n",
              "      <td>0.723548</td>\n",
              "      <td>0.744790</td>\n",
              "      <td>0.756536</td>\n",
              "      <td>0.562743</td>\n",
              "      <td>0.822054</td>\n",
              "      <td>0.886094</td>\n",
              "      <td>0.584060</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6186</td>\n",
              "      <td>0.9682</td>\n",
              "      <td>0.652083</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.818721</td>\n",
              "      <td>0.909195</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.732850</td>\n",
              "      <td>0.342857</td>\n",
              "      <td>0.594624</td>\n",
              "      <td>0.118519</td>\n",
              "      <td>0.383810</td>\n",
              "      <td>0.774167</td>\n",
              "      <td>0.642373</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.857173</td>\n",
              "      <td>0.886094</td>\n",
              "      <td>0.510940</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>1.0</td>\n",
              "      <td>59.0000</td>\n",
              "      <td>1554.0000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>261.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>474.000000</td>\n",
              "      <td>0.886094</td>\n",
              "      <td>2759.000000</td>\n",
              "      <td>2759</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             1        2          3          4    5          6           7  \\\n",
              "f1-score   0.0   0.6087     0.9630   0.641415  0.0   0.787927    0.889917   \n",
              "precision  0.0   0.6057     0.9580   0.650871  0.0   0.765447    0.872560   \n",
              "recall     0.0   0.6186     0.9682   0.652083  0.0   0.818721    0.909195   \n",
              "support    1.0  59.0000  1554.0000  16.000000  3.0  73.000000  261.000000   \n",
              "\n",
              "             8          9        10         11         12         13  \\\n",
              "f1-score   0.0   0.713996  0.442198   0.618922   0.162129   0.451739   \n",
              "precision  0.0   0.702552  0.757897   0.669004   0.337308   0.723548   \n",
              "recall     0.0   0.732850  0.342857   0.594624   0.118519   0.383810   \n",
              "support    8.0  69.000000  7.000000  31.000000  18.000000  35.000000   \n",
              "\n",
              "                  14         15         16          17  accuracy    macro avg  \\\n",
              "f1-score    0.757418   0.691908   0.346912    0.838568  0.886094     0.524398   \n",
              "precision   0.744790   0.756536   0.562743    0.822054  0.886094     0.584060   \n",
              "recall      0.774167   0.642373   0.272727    0.857173  0.886094     0.510940   \n",
              "support    80.000000  59.000000  11.000000  474.000000  0.886094  2759.000000   \n",
              "\n",
              "           weighted avg  \n",
              "f1-score              1  \n",
              "precision             1  \n",
              "recall                1  \n",
              "support            2759  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Divide total_cm by the number of runs to get the mean confusion matrix\n",
        "mean_cm = total_cm / 30\n",
        "\n",
        "# Sorting mean reports\n",
        "# Separate numeric and non-numeric rows\n",
        "numeric_reports = mean_reports[mean_reports.index.str.isnumeric()]\n",
        "non_numeric_reports = mean_reports[~mean_reports.index.str.isnumeric()]\n",
        "\n",
        "# Convert numeric indices to int and sort\n",
        "numeric_reports.index = numeric_reports.index.astype(int)\n",
        "numeric_reports = numeric_reports.sort_index()\n",
        "\n",
        "# Concatenate the DataFrames back together\n",
        "mean_reports = pd.concat([numeric_reports, non_numeric_reports])\n",
        "\n",
        "# Round the numeric values to 4 decimal places and convert the last column to integers\n",
        "mean_reports[mean_reports.columns[:3]] = mean_reports[mean_reports.columns[:3]].round(4)\n",
        "mean_reports[mean_reports.columns[-1]] = mean_reports[mean_reports.columns[-1]].round().astype(int)\n",
        "\n",
        "# Rename the columns to match the original classification report\n",
        "column_mapping = {str(old): str(old + 1) for old in range(0, 17)}\n",
        "mean_reports = mean_reports.rename(columns=column_mapping)\n",
        "\n",
        "# Finally, save the mean classification report to a CSV file\n",
        "mean_reports.to_csv('results/30x_classification_report.csv', sep=';', index=False)\n",
        "mean_reports # Visualize the mean classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a9c405f",
      "metadata": {
        "id": "7a9c405f"
      },
      "source": [
        "# Choosing the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72177273",
      "metadata": {
        "id": "72177273",
        "outputId": "8dd43a88-7f18-4538-90a9-fb70e3565532"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "      <th>run_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>precision</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.940075</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.784615</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.602273</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.810445</td>\n",
              "      <td>0.880029</td>\n",
              "      <td>0.519553</td>\n",
              "      <td>0.865333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>recall</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.525424</td>\n",
              "      <td>0.969112</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.698630</td>\n",
              "      <td>0.911877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.768116</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.883966</td>\n",
              "      <td>0.880029</td>\n",
              "      <td>0.431316</td>\n",
              "      <td>0.880029</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>f1-score</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.568807</td>\n",
              "      <td>0.954373</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.879852</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.675159</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.845610</td>\n",
              "      <td>0.880029</td>\n",
              "      <td>0.452825</td>\n",
              "      <td>0.867371</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>precision</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.672727</td>\n",
              "      <td>0.974526</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.902622</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.735294</td>\n",
              "      <td>...</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.709677</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.806818</td>\n",
              "      <td>0.896339</td>\n",
              "      <td>0.641845</td>\n",
              "      <td>0.894499</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recall</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.627119</td>\n",
              "      <td>0.960103</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.767123</td>\n",
              "      <td>0.923372</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.724638</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.542857</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.593220</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.898734</td>\n",
              "      <td>0.896339</td>\n",
              "      <td>0.563872</td>\n",
              "      <td>0.896339</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>f1-score</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.649123</td>\n",
              "      <td>0.967261</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.751678</td>\n",
              "      <td>0.912879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.729927</td>\n",
              "      <td>...</td>\n",
              "      <td>0.580645</td>\n",
              "      <td>0.644068</td>\n",
              "      <td>0.763006</td>\n",
              "      <td>0.673077</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.850299</td>\n",
              "      <td>0.896339</td>\n",
              "      <td>0.587775</td>\n",
              "      <td>0.893385</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>precision</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.971741</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.855263</td>\n",
              "      <td>0.871324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.730159</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.862069</td>\n",
              "      <td>0.903588</td>\n",
              "      <td>0.626664</td>\n",
              "      <td>0.900001</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      metric    0         1         2         3    4         5         6    7  \\\n",
              "0  precision  0.0  0.620000  0.940075  0.800000  0.0  0.784615  0.850000  0.0   \n",
              "1     recall  0.0  0.525424  0.969112  0.500000  0.0  0.698630  0.911877  0.0   \n",
              "2   f1-score  0.0  0.568807  0.954373  0.615385  0.0  0.739130  0.879852  0.0   \n",
              "3  precision  0.0  0.672727  0.974526  0.666667  0.0  0.736842  0.902622  0.0   \n",
              "4     recall  0.0  0.627119  0.960103  0.625000  0.0  0.767123  0.923372  0.0   \n",
              "5   f1-score  0.0  0.649123  0.967261  0.645161  0.0  0.751678  0.912879  0.0   \n",
              "6  precision  0.0  0.642857  0.971741  0.684211  0.0  0.855263  0.871324  0.0   \n",
              "\n",
              "          8  ...        11        12        13        14        15        16  \\\n",
              "0  0.602273  ...  0.000000  0.833333  0.787500  0.866667  0.000000  0.810445   \n",
              "1  0.768116  ...  0.000000  0.142857  0.787500  0.661017  0.000000  0.883966   \n",
              "2  0.675159  ...  0.000000  0.243902  0.787500  0.750000  0.000000  0.845610   \n",
              "3  0.735294  ...  0.692308  0.791667  0.709677  0.777778  1.000000  0.806818   \n",
              "4  0.724638  ...  0.500000  0.542857  0.825000  0.593220  0.363636  0.898734   \n",
              "5  0.729927  ...  0.580645  0.644068  0.763006  0.673077  0.533333  0.850299   \n",
              "6  0.750000  ...  0.700000  0.650000  0.758242  0.730159  0.833333  0.862069   \n",
              "\n",
              "   accuracy  macro avg  weighted avg  run_number  \n",
              "0  0.880029   0.519553      0.865333           1  \n",
              "1  0.880029   0.431316      0.880029           1  \n",
              "2  0.880029   0.452825      0.867371           1  \n",
              "3  0.896339   0.641845      0.894499           2  \n",
              "4  0.896339   0.563872      0.896339           2  \n",
              "5  0.896339   0.587775      0.893385           2  \n",
              "6  0.903588   0.626664      0.900001           3  \n",
              "\n",
              "[7 rows x 22 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the csv file that contains the sklearn's classification report for each run\n",
        "all_reports = pd.read_csv('results/all_reports.csv', sep=';')\n",
        "all_reports.head(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864282d7",
      "metadata": {
        "id": "864282d7",
        "outputId": "0403f50b-1006-46f2-ac13-0f50219f0c66"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAJOCAYAAADGYfSfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvLElEQVR4nO3df5id51kf+O+NpRBjGQVwcElsrCwxVFkbQ+SGsHHpCIPrxBB3i+lGC4ZQJS67OIXllwfcK8aAWRmWspTkomWj1Co/pIZAWF+26ziFGVhvm8Q2xBBHhJpUITGBBJIoliOInDz7xxxvx8qMdN7RzJxnznw+1zWX5pz3133PezRnvud9znOqtRYAAAD68TmTLgAAAICnE9QAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAN2pqldW1f3reLyvqKp3VdXjVfXP1+u4ALAcQQ2AU6qqI1V1vKqOVdVfVtUdVbVt0nWtsh9OMtdaO7e19q+qandVzVXV0ao6MuniANh8BDUAxvHNrbVtSV6Y5PIk/2LIxrWg5+eci5I8suj2E0nemOSHJlPO01XVlknXAMD66vlJE4DOtNYeS/IfklySJFX14qr6T1X18ap6uKpmnlq3quar6raq+n+TfDLJf3fy/qrqwqr6zar6SFX9dVW9bqnjVtXPV9UHquoTVfVQVf39RcteVFUPjpb9ZVX9y9H9z6yqXxnt9+NV9UBVnb/Evn8nye4krxtdNfzy1to7W2u/nOR94/xcquplVfWe0dDJx6rqBxctu3Y0rPITVfWnVXX16P7nVNWdVfXRqnq0ql69aJsfq6o3j+r/RJJXVtX2qtpfVR8aHeMnq+qs0frPr6rfHV0B/Kuq+vfj1A1AvwQ1AMZWVRcmeVmSP6iq5ya5O8lPJvnCJD+Y5Deq6tmLNrk+yQ1Jzk3y/pP2dVaSu0b370jy3CSHljn0A0m+anScX0vy61X1zNGyn0/y8621z0/yZUneNLr/O5NsT3Jhki9K8t1Jjp+849ba1yf5f5Lc2Frb1lr7kzF+FCfbn+SftdbOzUKI/Z1Rjy9K8u+ycGXuWUm+LsmR0TaHknwwyXOSXJfkp6rq6xft89okbx5t96tJ7kjyZJLnJ/nqJFcledVo3Z9Icl+SL0hyQZJfWEEPAHREUANgHL9VVR9Pcn+S303yU0m+Pck9rbV7Wmufaa29LcmDWQhyT7mjtfZIa+3J1tqJk/b5oiyElB9qrT3RWvub1tqSE4i01n6ltfbXo/38bJLPTfIVo8Unkjy/qs5rrR1rrb190f1flOT5rbVPt9Yeaq194ox/Eks7keQFVfX5rbWPtdZ+f3T/3iRvbK29bfQzeqy19sejwPuSJDeN+n5Xkjck+Y5F+/zPrbXfaq19JsnnZ+Hn+n2jn9WHk/xcklcsOv5FSZ5zqp8jABuHoAbAOP5Ra+1ZrbWLWmv/a2vteBaCwbeOhhV+fBTkrkjyJYu2+8Ap9nlhkve31p483cGr6ger6vBoaN/Hs3Cl7LzR4r1JvjzJH4+GN37T6P5fTvLWJIeq6s+r6qerauuAnper5UdHQySPVdW/Ht39LVkIUu8fDUH82kU9/ukSu3lOko+21h5fdN/7s3BV8SmLf3YXJdma5EOLftb/JskXj5b/cJJK8s6qeqSq/ukZtAhAB7w5GYCV+kCSX26tvfoU67TTbP+lVbXlVGFt9H60H05yZZJHWmufqaqPZSGYpLX2X5LsGU1W8o+TvLmqvqi19kSSW5PcWlU7ktyT5L1ZGKa4Yq21n8rCFcXF9z2Q5NpRELwxC8MvLxz1+GVL7ObPk3xhVZ27KKx9aZLHFu920fcfSPK3Sc5b6mfVWvuLJK9Okqq6Isl/rKrfa609uoIWAeiAK2oArNSvJPnmqvqHVXXWaPKOmaq6YMzt35nkQ0n2VdU5o+1fssR652bhvVkfSbKlql6bhaGASZKq+vaqevZoiODHR3d/pham2L909F64T2RheOBnximsqj5n9B64rQs365lV9Yxl1n1GVX1bVW0fDe/8xKLj7E/yXVV15Wifz62qv9ta+0CS/5Tkfx/t+yuzcGXwV5Y6RmvtQ1l4D9rPVtXnj/b1ZVX1D0Y1fOuin/vHshDyxuoVgD4JagCsyChsXJvkR7MQoj6QhUkzxnpuaa19Osk3Z2FyjD/LwsQa/9MSq741yb1J/iQLwwP/Jk8fFnh1kkeq6lgWJhZ5xWho5t/JwmQcn0hyOAvvrfvlMdv7uixMPHJPFq50Hc9CUFrO9UmOjGZo/O4k3zbq8Z1JvisL7yc7OqrhotE2e7IwicqfJ3lLkltaa//xFMf4jiTPSPKeLISxN+e/DTP9e0neMfoZ3Jnke1trY81YCUCfqrVTjUoBAABgvbmiBgAA0BlBDQAAoDOCGgAAQGcENQAAgM5M7HPUzjvvvLZjx441PcYTTzyRc845Z02Psdb00Idp6CGZjj700Idp6CGZjj700Idp6CGZjj700Ac9jOehhx76q9bas5daNrGgtmPHjjz44INreoz5+fnMzMys6THWmh76MA09JNPRhx76MA09JNPRhx76MA09JNPRhx76oIfxVNX7l1tm6CMAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADozGmDWlW9sao+XFXvXmZ5VdW/qqpHq+oPq+qFq18mAADA5jHOFbU7klx9iuUvTXLx6OuGJL945mUBAABsXqcNaq2130vy0VOscm2Sf9cWvD3Js6rqS1arQAAAgM2mWmunX6lqR5K7WmuXLLHsriT7Wmv3j27/dpKbWmsPLrHuDVm46pbzzz9/16FDh86s+tM4duxYtm3btqbHWGt66MM09JBMRx966MM09JBMRx966MM09JBMRx966IMexrN79+6HWmuXL7Vsy5oe+SSttV9K8ktJcvnll7eZmZk1Pd78/HzW+hhrTQ99mIYekunoQw99mIYekunoQw99mIYekunoQw990MOZW41ZHx9LcuGi2xeM7gMAAGAFViOo3ZnkO0azP744ydHW2odWYb8AAACb0mmHPlbVwSQzSc6rqg8muSXJ1iRprf3rJPckeVmSR5N8Msl3rVWxAAAAm8Fpg1prbc9plrck37NqFQEAAGxyqzH0EQAAgFUkqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdOe0HXsO4qmrwNguflw4AACzmihqrprW25NdFN9217DIAAOCzCWoAAACdMfSRwS679b4cPX5i0DY7Zu8ee93tZ2/Nw7dcNbQsAACYGoIagx09fiJH9l0z9vrz8/OZmZkZe/0hoQ4AAKaRoMZg5+6czaUHZodtdGDI/pNk/CAIAADTRlBjsMcP71vT/W8/e+ua7h8AAHonqDHYkGGPycJQxqHbAADAZmbWRwAAgM64osaqOdUHXtftS9/vs9QAAOCzuaLGqlnuQ63n5uZ84DUAAAwgqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzghqAAAAndky6QIAplVVDd6mtbYGlQAAG40ragBrpLW25NdFN9217DIAgERQAwAA6I6gBgAA0BlBDQAAoDOCGgAAQGcENQAAgM4IagAAAJ3xOWoAZ+iyW+/L0eMnBm2zY/busdfdfvbWPHzLVUPLAgA2MEEN4AwdPX4iR/ZdM/b68/PzmZmZGXv9IaEOAJgOhj4CAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzpieH+AMnbtzNpcemB220YEh+0+S8af/BwA2PkEN4Aw9fnifz1EDAFaVoY8AAACdEdQAAAA6I6gBAAB0RlADAADojMlEAFbB4Ak/7h1//e1nbx1YDQCw0QlqAGdoyIyPyUKoG7oNALC5GPoIAADQGVfUgC5V1eBtWmtrUAkAwPpzRQ3oUmttya+Lbrpr2WUAANNCUAMAAOiMoAYAANAZQQ0AgA3v4MGDueSSS3LllVfmkksuycGDByddEpwRk4kAALChHTx4MDfffHP279+fT3/60znrrLOyd+/eJMmePXsmXB29W8kEZsnaT2LmihoAABvabbfdlv3792f37t3ZsmVLdu/enf379+e2226bdGlsACuZwGw9JjET1AAA2NAOHz6cK6644mn3XXHFFTl8+PCEKoIzJ6gBALCh7dy5M/fff//T7rv//vuzc+fOCVUEZ8571ADWyKnGvNftS9/v8+AAhrv55puzd+/e//89anNzc9m7d6+hj2xoghrAGlkudM3Pz2dmZmZ9iwGYYk9NGPKa17wmhw8fzs6dO3PbbbeZSIQNTVADAGDD27NnT/bs2ePFMKaG96gBAAB0xhU1AABg6l126305evzEoG12zN49aP3tZ2/Nw7dcNWib5QhqAADA1Dt6/ESO7Ltm7PVXMox2aLA7FUMfAQAAOiOoAQAAdMbQRwAAYOqdu3M2lx6YHbbRgaHHSJLxh1eeiqAGAABMvccP7/MeNQAAAFZOUAMAAOiMoY8AAMCmMHho4r3DP0dttQhqAADA1Bvy/rRkIdQN3WY1GfoIAADQGUENAACgM4IaAABAZwQ1AACAzghqAAAAnTHrIzBRl916X44ePzFomyFT624/e2sevuWqoWUB0LmqGrxNa20NKoG1IajBIiv5pZ/4xX8mjh4/MWjq2/n5+czMzIy9/uDPSwFgQ1juuXfSU6qz8Zzq77+6ffnt1vrvP0MfYZHW2pJfF91017LLhDQAgI1rub/v5ubmJvr3n6AGAADQGUENAACgM4IaAABAZ8YKalV1dVW9t6oerarZJZZ/aVXNVdUfVNUfVtXLVr9UAACAzeG0sz5W1VlJXp/kG5N8MMkDVXVna+09i1b7F0ne1Fr7xap6QZJ7kuxYg3oBYBCzuQKwEY1zRe1FSR5trb2vtfapJIeSXHvSOi3J54++357kz1evRABYuVPN2HWqGV0BYJLqdE9GVXVdkqtba68a3b4+yde01m5ctM6XJLkvyRckOSfJN7TWHlpiXzckuSFJzj///F2HDh1arT6WdOzYsWzbtm1Nj7HW9NCHV977RO64+pxJl3HGejwXQ3+2Q3vo8dz1eB6GmoYekj4fH0NNw7nQQz+moQ//r9fX7t27B28zNze3BpWsvvU4D7t3736otXb5kgtP9UrjKMRdl+QNi25fn+R1J63z/Ul+YPT91yZ5T5LPOdV+d+3a1dba3Nzcmh9jremhDxfddNekS1gVPZ6LoT/boT30eO56PA9DTUMPrfX5+BhqGs6FHvoxDX34f90H52E8SR5sy+SlcYY+PpbkwkW3Lxjdt9jeJG8aBb//nOSZSc4bY98AAACcZJyg9kCSi6vqeVX1jCSvSHLnSev8WZIrk6SqdmYhqH1kNQsFAADYLE4b1FprTya5MclbkxzOwuyOj1TVj1fVy0er/UCSV1fVw0kOJnnl6FIeAAAAA512ev4kaa3dk4Up9xff99pF378nyUtWtzQAAIDNaawPvAYAAGD9jHVFDWCtnLtzNpcemB220YEh+0+Sa4btHwBgwgQ1YKIeP7wvR/aNH6Tm5+czMzMz9vo7Zu9eQVUAAJMlqAEA0KXLbr0vR4+fGLzdkBfptp+9NQ/fctXgY8BaE9QAAOjS0eMnBo26SIy8YHqYTAQAAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM1smXQAAAGxGVTV4m9baGlRCjwQ1AGBd+KMUnm65x/eO2btzZN8161wNvTH0EQBYF621Jb8uuumuZZcBbFauqAETt2P27mEb3Dv++tvP3jqwGgCAyRPUgIkaOrTDcBCWc9mt9+Xo8RODtxvyQsH2s7fm4VuuGnwMYGXO3TmbSw/MDt/wwJBjJInnFfojqAEwFY4ePzE4xM/Pz2dmZmbs9Qdf/QXOyOOH9/l/zablPWoAAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzvjAawAAurWiD6S+d/xttp+9dfj+YR0IagAAdOnIvmsGb7Nj9u4VbQe9MfQRAACgM66oAcAGUFWDt2mtrUElbHQreSwlHk+w3lxRA4ANoLW25NdFN9217DJYynKPF48n6IsrakCXTvWKb92+9P3+kACgR5fdel+OHj8xaJshk6hsP3trHr7lqqFl0TlBDejScqFrfn4+MzMz61sMAJyBo8dPDJrgZOhz3YpmxqR7hj4CAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzpievxOn+syo5fjMKAAAmE6uqHWitbbk10U33bXsMgAAYDq5ogbAVDh352wuPTA7fMMDQ46RJON/aC0ArJSgBsBUePzwvhzZNyxEzc/PZ2ZmZuz1d8zePbAqAFgZQx8BAAA644oam9Jlt96Xo8dPDNpm6Cvp28/emodvuWrQNgAAkAhqbFJHj58YNERq6PCoxBApAABWztBHAACAzghqAAAAnRHUAAAAOiOoAQAAdMZkIgBMjRVN4nPv+NtsP3vr8P0Da6Kqll92+9L3t9bWqJpTO3fnbC49MDtsowND9p8kwz5Hkv4JagBMhaEfdp0sBLuVbAdM3nKhayUzNa+1xw/vW9PZps00PZ0MfQQAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOmPURAFhVl916X44ePzFomyGz1m0/e2sevuWqoWXBRA2emdFHh2x6ghoAsKqOHj9hKnJYZOjHgPjoEBJDHwEAALojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0ZsukC9hsLrv1vhw9fmLQNjtm7x573e1nb83Dt1w1tCwAAKAjgto6O3r8RI7su2bs9efn5zMzMzP2+kNC3WZ27s7ZXHpgdthGB4YeI0nGP9cAsJpW8uJw4gVi6IWgxqb0+OF9axqYE6EZgMka+uJw4gVi6In3qAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACd8TlqAEy1qjr18tuXvr+1tgbVAMB4XFEDYKq11pb9mpubW3YZAEySoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADozJZJFwAATJdzd87m0gOzwzY6MGT/SXLNsP0DbDBjBbWqujrJzyc5K8kbWmv7lljnnyT5sSQtycOttf95FesEADaIxw/vy5F94wep+fn5zMzMjL3+jtm7V1AVwMZy2qBWVWcleX2Sb0zywSQPVNWdrbX3LFrn4iQ/kuQlrbWPVdUXr1XBAAAA026cK2ovSvJoa+19SVJVh5Jcm+Q9i9Z5dZLXt9Y+liSttQ+vdqEAADBNqmr5ZbcvfX9rbY2qoTd1upNdVdclubq19qrR7euTfE1r7cZF6/xWkj9J8pIsDI/8sdbavUvs64YkNyTJ+eefv+vQoUOr1MbSjh07lm3btq3pMYZ65b1P5I6rzxl7/aE9DN3/etiM52Elx1gPPZ6LofTQh2noIemzj+/57SfyxIm12/85W5PXX7m2v5s81/VhJT8n56IP09BDj4+NodbjPOzevfuh1trlSy5srZ3yK8l1WXhf2lO3r0/yupPWuSvJW5JsTfK8JB9I8qxT7XfXrl1trc3Nza35MYa66Ka7Bq0/tIeh+18Pm/E8rOQY66HHczGUHvowDT201mcf0/A8MQ09DDUNj6XWnIteTEMPPT42hlqP85DkwbZMXhpn6ONjSS5cdPuC0X2LfTDJO1prJ5L816r6kyQXJ3lgnCS5mZgJCwAAOJ1xgtoDSS6uqudlIaC9IsnJMzr+VpI9Sf5tVZ2X5MuTvG8V65waZsICAABO57QfeN1aezLJjUnemuRwkje11h6pqh+vqpePVntrkr+uqvckmUvyQ621v16rogEAAKbZWJ+j1lq7J8k9J9332kXftyTfP/oCAADgDJz2ihoAAADrS1ADAADojKAGAADQmbHeowbTaPAMmfcOW3/72VuH7R8AAEYENTalIR+RkCyEuqHbADB9qmrwNgtzrsHGdtmt9+Xo8RODthn6ovj2s7fm4VuuGrTNNBPUAADGtFzo8oIe0+7o8RNr+lnAic8DPpmgBgCsurUcXm5oObAZCGoAwKoyvBzgzJn1EQAAoDOCGgAAQGcMfZwA4/YBAIBTEdTWmXH7AADA6Rj6CAAA0BlBDQAAoDOCGgAAQGcENQAAgM4IagAAAJ0R1AAAADojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADozJZJFwAAwOo7d+dsLj0wO3zDA0OOkSTXDD8GcFqCGgDAFHr88L4c2TcsRM3Pz2dmZmbs9XfM3j2wKmBchj4CAAB0RlADAADojKGPnaiq5ZfdvvT9rbU1qgYAAJgkV9Q60Vpb8mtubm7ZZQAAwHQS1AAAADojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnfI4aALAufGYowPhcUQMA1oXPDAUYn6AGAADQGUENAACgM4IaAABAZwQ1AACAzghqAAAAnRHUAAAAOiOoAQAAdEZQAwAA6IygBgAA0BlBDQAAoDOCGgAAQGcENQAAgM4IagAAAJ0R1AAAADojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADozJZJFwA9qarll92+/HattTWoBgCAzcoVNViktbbk19zc3LLLhDQAAFaboAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdMT0/AHTk3J2zufTA7LCNDgzZf5JcM2z/AKw7QQ0AOvL44X05sm/8IDU/P5+ZmZmx198xe/cKqgJgvRn6CAAA0BlBDQAAoDOCGgAAQGcENQAAgM4IagAAAJ0R1ACAiTh48GAuueSSXHnllbnkkkty8ODBSZcE0A3T8wMA6+7gwYO5+eabs3///nz605/OWWedlb179yZJ9uzZM+HqACbPFTUAYN3ddttt2b9/f3bv3p0tW7Zk9+7d2b9/f2677bZJlwbQBUENAFh3hw8fzhVXXPG0+6644oocPnx4QhUB9EVQAwDW3c6dO3P//fc/7b77778/O3funFBFAH0R1ACAdXfzzTdn7969mZuby5NPPpm5ubns3bs3N99886RLA+iCyUQAgHX31IQhr3nNa3L48OHs3Lkzt912m4lEAEYENQBgIvbs2ZM9e/Zkfn4+MzMzky4HoCuGPgIAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnxgpqVXV1Vb23qh6tqtlTrPctVdWq6vLVKxEAAGBzOW1Qq6qzkrw+yUuTvCDJnqp6wRLrnZvke5O8Y7WLBAAA2EzGuaL2oiSPttbe11r7VJJDSa5dYr2fSHJ7kr9ZxfoAAAA2nWqtnXqFquuSXN1ae9Xo9vVJvqa1duOidV6Y5ObW2rdU1XySH2ytPbjEvm5IckOSnH/++bsOHTq0ao0s5dixY9m2bduaHmOt6aEP09BDMh196KEP09BD0mcfr7z3idxx9Tljrz+0h6H7Xw89noehevy5rqQmj6c+9NjDWv9uWskx1tp6nIfdu3c/1Fpb+m1jrbVTfiW5LskbFt2+PsnrFt3+nCTzSXaMbs8nufx0+921a1dba3Nzc2t+jLWmhz5MQw+tTUcfeujDNPTQWp99XHTTXYPWH9rD0P2vhx7Pw1A9/lxXUpPHUx967GGtfzet5BhrbT3OQ5IH2zJ5aZyhj48luXDR7QtG9z3l3CSXJJmvqiNJXpzkThOKAAAArMw4Qe2BJBdX1fOq6hlJXpHkzqcWttaOttbOa63taK3tSPL2JC9vSwx9BAAA4PROG9Raa08muTHJW5McTvKm1tojVfXjVfXytS4QAABgs9kyzkqttXuS3HPSfa9dZt2ZMy8LAABg8xorqAEAAJvXuTtnc+mB2WEbHRh6jCS5ZthGU0xQAwAATunxw/tyZN/4IWp+fj4zMzODjrFj9u6BVU23cSYTAQAAYB0JagAAAJ0R1AAAADojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzghqAAAAnRHUAAAAOiOoAQAAdEZQAwAA6IygBgAA0BlBDQAAoDOCGgAAQGcENQAAgM4IagAAAJ0R1AAAADojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzghqAAAAnRHUAAAAOiOoAQAAdEZQAwAA6IygBgAA0BlBDQAAoDOCGgAAQGcENQAAgM5smXQBAMDT7Zi9e9gG946//vaztw6sBoBJENQAoCNH9l0zaP0ds3cP3gaA/hn6CAAA0BlX1AAATnLZrffl6PETg7YZOmR1+9lb8/AtVw3aBtg8BDUAgJMcPX5i0JDS+fn5zMzMDDrG4PciApuKoY8AAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzghqAAAAnRHUAAAAOiOoAQAAdEZQAwAA6IygBgAA0Jktky4AAIC1sWP27uEb3Tv+NtvP3jp8/8BYBDUAgCl0ZN81g7fZMXv3irYDVp+hjwAAAJ0R1AAAADojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzghqAAAAnRHUAAAAOiOoAQAAdEZQAwAA6IygBgAA0JmxglpVXV1V762qR6tqdonl319V76mqP6yq366qi1a/VAAAgM3htEGtqs5K8vokL03ygiR7quoFJ632B0kub619ZZI3J/np1S4UAABgsxjnitqLkjzaWntfa+1TSQ4luXbxCq21udbaJ0c3357kgtUtEwAAYPOo1tqpV6i6LsnVrbVXjW5fn+RrWms3LrP+65L8RWvtJ5dYdkOSG5Lk/PPP33Xo0KEzLP/Ujh07lm3btq3pMdaaHvowDT0k09GHHvowDT0k09HHK+99Indcfc6kyzgjPZ6HoT/XlfTQ47nrsaahenw8DdVjD5vx/8R6nIfdu3c/1Fq7fMmFrbVTfiW5LskbFt2+Psnrlln327NwRe1zT7ffXbt2tbU2Nze35sdYa3rowzT00Np09KGHPkxDD61NRx8X3XTXpEs4Yz2eh6E/15X00OO567GmoXp8PA3VYw+b8f/EepyHJA+2ZfLSljGC3mNJLlx0+4LRfU9TVd+Q5OYk/6C19rfjpkgAAACebpz3qD2Q5OKqel5VPSPJK5LcuXiFqvrqJP8myctbax9e/TIBAAA2j9MGtdbak0luTPLWJIeTvKm19khV/XhVvXy02s8k2Zbk16vqXVV15zK7AwAA4DTGGfqY1to9Se456b7XLvr+G1a5LgAAgE1rrA+8BgAAYP0IagAAAJ0R1AAAADojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzghqAAAAnRHUAAAAOiOoAQAAdEZQAwAA6IygBgAA0BlBDQAAoDOCGgAAQGcENQAAgM4IagAAAJ0R1AAAADojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzghqAAAAnRHUAAAAOiOoAQAAdGbLpAsAAOjNuTtnc+mB2WEbHRh6jCS5ZthGwKYhqAEAnOTxw/tyZN/4IWp+fj4zMzODjrFj9u6BVQGbiaGPAAAAnRHUAAAAOiOoAQAAdEZQAwAA6IygBgAA0BlBDQAAoDOCGgAAQGcENQAAgM4IagAAAJ0R1AAAADojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzghqAAAAnRHUAAAAOiOoAQAAdEZQAwAA6IygBgAA0BlBDQAAoDOCGgAAQGcENQAAgM4IagAAAJ0R1AAAADojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZ8YKalV1dVW9t6oerarZJZZ/blX9+9Hyd1TVjlWvFAAAYJM4bVCrqrOSvD7JS5O8IMmeqnrBSavtTfKx1trzk/xckttXu1AAAIDNYpwrai9K8mhr7X2ttU8lOZTk2pPWuTbJgdH3b05yZVXV6pUJAACweVRr7dQrVF2X5OrW2qtGt69P8jWttRsXrfPu0TofHN3+09E6f3XSvm5IckOSnH/++bsOHTo0dqGvef9rxl73TPzCRb+wLscZ17Fjx7Jt27ZJl3FG9LA2/J/YuHrsweOpf7t37x68zdzc3BpUsvp6PA+vvPeJJe9//+3fNHhfF91015L3n7M1ef2V5wze35layWMp8XhaTz32MM3/J5azHudh9+7dD7XWLl9yYWvtlF9JrkvyhkW3r0/yupPWeXeSCxbd/tMk551qv7t27WprbW5ubs2Psdb00Idp6KG16ehDD32Yhh5am44+9NCHaeihtenoQw990MN4kjzYlslL4wx9fCzJhYtuXzC6b8l1qmpLku1J/nqcFAkAAMDTjRPUHkhycVU9r6qekeQVSe48aZ07k3zn6PvrkvzOKCECAAAw0JbTrdBae7Kqbkzy1iRnJXlja+2RqvrxLFyquzPJ/iS/XFWPJvloFsIcAAAAK3DaoJYkrbV7ktxz0n2vXfT93yT51tUtDQAAYHMa6wOvAQAAWD+CGgAAQGcENQAAgM4IagAAAJ0R1AAAADojqAEAAHRGUAMAAOiMoAYAANAZQQ0AAKAzghoAAEBnBDUAAIDOCGoAAACdEdQAAAA6I6gBAAB0RlADAADojKAGAADQGUENAACgM4IaAABAZwQ1AACAzlRrbTIHrvpIkvev8WHOS/JXa3yMtaaHPkxDD8l09KGHPkxDD8l09KGHPkxDD8l09KGHPuhhPBe11p691IKJBbX1UFUPttYun3QdZ0IPfZiGHpLp6EMPfZiGHpLp6EMPfZiGHpLp6EMPfdDDmTP0EQAAoDOCGgAAQGemPaj90qQLWAV66MM09JBMRx966MM09JBMRx966MM09JBMRx966IMeztBUv0cNAABgI5r2K2oAAAAbjqAGAADQmakMalV1dVW9t6oerarZSdezElX1xqr6cFW9e9K1rFRVXVhVc1X1nqp6pKq+d9I1DVVVz6yqd1bVw6Mebp10TStVVWdV1R9U1V2TrmUlqupIVf1RVb2rqh6cdD0rVVXPqqo3V9UfV9XhqvraSdc0RFV9xegcPPX1iar6vknXNVRV/W+j/9PvrqqDVfXMSdc0VFV976j+RzbSOVjq+a2qvrCq3lZV/2X07xdMssbTWaaHbx2di89UVfdTki/Tw8+Mfjf9YVW9paqeNcESx7JMHz8x6uFdVXVfVT1nkjWezqn+5quqH6iqVlXnTaK2cS1zHn6sqh5b9HzxsknWeDrLnYeqes3o/8UjVfXT61nT1AW1qjoryeuTvDTJC5LsqaoXTLaqFbkjydWTLuIMPZnkB1prL0jy4iTfswHPxd8m+frW2mVJvirJ1VX14smWtGLfm+TwpIs4Q7tba1+1wT+X5eeT3Nta+7tJLssGOyettfeOzsFXJdmV5JNJ3jLZqoapqucm+edJLm+tXZLkrCSvmGxVw1TVJUleneRFWXgcfVNVPX+yVY3tjnz289tskt9urV2c5LdHt3t2Rz67h3cn+cdJfm/dq1mZO/LZPbwtySWtta9M8idJfmS9i1qBO/LZffxMa+0rR7+n7kry2vUuaqA7ssTffFV1YZKrkvzZehe0Andk6b9bf+6p54zW2j3rXNNQd+SkHqpqd5Jrk1zWWvvvk/wf61nQ1AW1LDxpPdpae19r7VNJDmXhB7yhtNZ+L8lHJ13HmWitfai19vuj7x/Pwh+kz51sVcO0BcdGN7eOvjbcDDxVdUGSa5K8YdK1bGZVtT3J1yXZnySttU+11j4+0aLOzJVJ/rS19v5JF7ICW5KcXVVbknxekj+fcD1D7UzyjtbaJ1trTyb53SyEhO4t8/x2bZIDo+8PJPlH61nTUEv10Fo73Fp774RKGmyZHu4bPZ6S5O1JLlj3wgZapo9PLLp5Tjp/3j7F33w/l+SH03n9ydT83bpUD/9Lkn2ttb8drfPh9axpGoPac5N8YNHtD2aDhYNpVFU7knx1kndMuJTBRkMG35Xkw0ne1lrbcD0k+T+z8Mv+MxOu40y0JPdV1UNVdcOki1mh5yX5SJJ/OxqG+oaqOmfSRZ2BVyQ5OOkihmqtPZaFV0X/LMmHkhxtrd032aoGe3eSv19VX1RVn5fkZUkunHBNZ+L81tqHRt//RZLzJ1kMSZJ/muQ/TLqIlaqq26rqA0m+Lf1fUfssVXVtksdaaw9PupYzdONoGOobex/SvIwvz8Lv2ndU1e9W1d9bz4NPY1CjM1W1LclvJPm+k17l2hBaa58eDZ+4IMmLRkOONoyq+qYkH26tPTTpWs7QFa21F2ZhWPP3VNXXTbqgFdiS5IVJfrG19tVJnkj/Q7yWVFXPSPLyJL8+6VqGGv2xcG0WgvNzkpxTVd8+2aqGaa0dTnJ7kvuS3JvkXUk+PcmaVktb+Nyg7q8gTLOqujkLb1/41UnXslKttZtbaxdmoYcbJ13PEKMXX340GzBgnuQXk3xZFt468qEkPzvRalZmS5IvzMJbeH4oyZuqqtbr4NMY1B7L019VvGB0HxNQVVuzENJ+tbX2m5Ou50yMhqjNZeO9d/AlSV5eVUeyMBT466vqVyZb0nCjqyBPDTt4SxaGOW80H0zywUVXZd+cheC2Eb00ye+31v5y0oWswDck+a+ttY+01k4k+c0k/8OEaxqstba/tbartfZ1ST6WhfcUbVR/WVVfkiSjf9d1eBH/TVW9Msk3Jfm2Nh0ftvurSb5l0kUM9GVZeCHp4dFz9wVJfr+q/s5EqxqotfaXoxe7P5Pk/8rGfd7+zdFbYd6ZhZFJ6zaxyzQGtQeSXFxVzxu94vuKJHdOuKZNafSKw/4kh1tr/3LS9axEVT37qVmvqursJN+Y5I8nWtRArbUfaa1d0FrbkYX/D7/TWttQVw+q6pyqOvep77Pw5uoNNyNqa+0vknygqr5idNeVSd4zwZLOxJ5swGGPI3+W5MVV9Xmj31NXZoNN6pIkVfXFo3+/NAvvT/u1yVZ0Ru5M8p2j778zyf89wVo2raq6OgvD5F/eWvvkpOtZqaq6eNHNa7Pxnrf/qLX2xa21HaPn7g8meeHoOWTDeOrFl5H/MRvweTvJbyXZnSRV9eVJnpHkr9br4FvW60DrpbX2ZFXdmOStWZjJ642ttUcmXNZgVXUwyUyS86rqg0luaa3tn2xVg70kyfVJ/mj0Hq8k+dENMOvPYl+S5MBoNtHPSfKm1tqGnN5+gzs/yVtGow22JPm11tq9ky1pxV6T5FdHLyS9L8l3TbiewUZh+RuT/LNJ17ISrbV3VNWbk/x+FoZ3/UGSX5psVSvyG1X1RUlOJPmejTIxzVLPb0n2ZWFI0d4k70/yTyZX4ekt08NHk/xCkmcnubuq3tVa+4eTq/LUlunhR5J8bpK3jX7fvr219t0TK3IMy/TxstELYp/JwuNpw/Ww0f7mW+Y8zFTVV2VhKPORdP6csUwPb0zyxtGU/Z9K8p3reaW5puOqNgAAwPSYxqGPAAAAG5qgBgAA0BlBDQAAoDOCGgAAQGcENQAAgM4IagAAAJ0R1AAAADrz/wG0a6Y0BgDS2AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the per class f1-scores in a boxplot\n",
        "\n",
        "# Filter the DataFrame\n",
        "f1_scores = all_reports[all_reports['metric'] == 'f1-score']\n",
        "\n",
        "# Drop non-numeric columns if any\n",
        "#numeric_columns = f1_scores.select_dtypes(include=[np.number]).columns.tolist()\n",
        "f1_scores = f1_scores[['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16']]\n",
        "\n",
        "# Plot the boxplots\n",
        "plt.figure(figsize=(15, 10))\n",
        "f1_scores.boxplot()\n",
        "plt.title('Per class f1-scores')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7532368",
      "metadata": {
        "id": "a7532368"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean and standard deviation of the f1-scores, precision, and recall\n",
        "f1_scores = all_reports[all_reports['metric'] == 'f1-score']\n",
        "precision_scores = all_reports[all_reports['metric'] == 'precision']\n",
        "recall_scores = all_reports[all_reports['metric'] == 'recall']\n",
        "\n",
        "mean_f1_scores = f1_scores.mean() * 100\n",
        "std_f1_scores = f1_scores.std() * 100\n",
        "\n",
        "mean_precision_scores = precision_scores.mean() * 100\n",
        "std_precision_scores = precision_scores.std()\n",
        "\n",
        "mean_recall_scores = recall_scores.mean() * 100\n",
        "std_recall_scores = recall_scores.std() * 100\n",
        "\n",
        "# Create a summary DataFrame\n",
        "f1_scores_summary = mean_f1_scores.map('{:.2f}'.format) + \" (\" + std_f1_scores.map('{:.2f}'.format) + \")\"\n",
        "precision_scores_summary = mean_precision_scores.map('{:.2f}'.format) + \" (\" + std_precision_scores.map('{:.2f}'.format) + \")\"\n",
        "recall_scores_summary = mean_recall_scores.map('{:.2f}'.format) + \" (\" + std_recall_scores.map('{:.2f}'.format) + \")\"\n",
        "\n",
        "scores_summary = pd.DataFrame({'f1-score': f1_scores_summary,\n",
        "                               'precision': precision_scores_summary,\n",
        "                               'recall': recall_scores_summary})\n",
        "\n",
        "scores_summary.to_csv('results/scores_summary.csv', sep=';', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "317d276a",
      "metadata": {
        "id": "317d276a",
        "outputId": "e5d9e300-5960-4e77-abad-26c1f275fc1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Identify the index of the model that achieved the highest f1-score\n",
        "all_reports[all_reports['metric'] == 'f1-score']['macro avg'].reset_index(drop=True).idxmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd6b6250",
      "metadata": {
        "id": "cd6b6250"
      },
      "source": [
        "# **Considering an additional class:**\n",
        "When the maximum predicted probability is less than 80%, we consider the sample as no related to any Sustainable Development Goal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8721e59f",
      "metadata": {
        "id": "8721e59f"
      },
      "outputs": [],
      "source": [
        "# Load dataset and adjust labels\n",
        "df = pd.read_csv('original_and_preprocessed.csv', sep=';', encoding='utf-8', usecols=['processed_abstract_text', 'label'])\n",
        "df['label'] = df['label'] - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5597b81c",
      "metadata": {
        "id": "5597b81c",
        "outputId": "a24c3529-2992-4c17-b246-54630ca75228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are the counts equal? True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/ubuntu/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/home/ubuntu/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.971741</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.855263</td>\n",
              "      <td>0.871324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.677419</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.730159</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.862069</td>\n",
              "      <td>0.903588</td>\n",
              "      <td>0.626664</td>\n",
              "      <td>0.900001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.610169</td>\n",
              "      <td>0.973616</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.890411</td>\n",
              "      <td>0.908046</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.677419</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.779661</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.843882</td>\n",
              "      <td>0.903588</td>\n",
              "      <td>0.603239</td>\n",
              "      <td>0.903588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.626087</td>\n",
              "      <td>0.972678</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.872483</td>\n",
              "      <td>0.889306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.744526</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.677419</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.693333</td>\n",
              "      <td>0.807018</td>\n",
              "      <td>0.754098</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.852878</td>\n",
              "      <td>0.903588</td>\n",
              "      <td>0.608018</td>\n",
              "      <td>0.901015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>1.0</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>1554.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>261.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>474.000000</td>\n",
              "      <td>0.903588</td>\n",
              "      <td>2759.000000</td>\n",
              "      <td>2759.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0          1            2          3    4          5           6  \\\n",
              "precision  0.0   0.642857     0.971741   0.684211  0.0   0.855263    0.871324   \n",
              "recall     0.0   0.610169     0.973616   0.812500  0.0   0.890411    0.908046   \n",
              "f1-score   0.0   0.626087     0.972678   0.742857  0.0   0.872483    0.889306   \n",
              "support    1.0  59.000000  1554.000000  16.000000  3.0  73.000000  261.000000   \n",
              "\n",
              "             7          8         9         10         11         12  \\\n",
              "precision  0.0   0.750000  0.666667   0.677419   0.700000   0.650000   \n",
              "recall     0.0   0.739130  0.571429   0.677419   0.388889   0.742857   \n",
              "f1-score   0.0   0.744526  0.615385   0.677419   0.500000   0.693333   \n",
              "support    8.0  69.000000  7.000000  31.000000  18.000000  35.000000   \n",
              "\n",
              "                  13         14         15          16  accuracy    macro avg  \\\n",
              "precision   0.758242   0.730159   0.833333    0.862069  0.903588     0.626664   \n",
              "recall      0.862500   0.779661   0.454545    0.843882  0.903588     0.603239   \n",
              "f1-score    0.807018   0.754098   0.588235    0.852878  0.903588     0.608018   \n",
              "support    80.000000  59.000000  11.000000  474.000000  0.903588  2759.000000   \n",
              "\n",
              "           weighted avg  \n",
              "precision      0.900001  \n",
              "recall         0.903588  \n",
              "f1-score       0.901015  \n",
              "support     2759.000000  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This cell is responsible to find the exact same split that was used by the model with best metrics in the 30x runs\n",
        "\n",
        "# The number of the run with the best metrics to load the respective mode weights\n",
        "run_number = 2\n",
        "\n",
        "X = df['processed_abstract_text'].reset_index(drop=True)\n",
        "y = df['label'].reset_index(drop=True)\n",
        "\n",
        "unique_labels = np.unique(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=run_number, stratify=y, shuffle=True) # The random state is the run number\n",
        "\n",
        "# Get unique labels in y_test and y\n",
        "unique_test_labels = np.unique(y_test)\n",
        "\n",
        "# Check if not all labels are represented in the test set\n",
        "if set(unique_test_labels) != set(unique_labels):\n",
        "    missing_labels = set(unique_labels) - set(unique_test_labels)\n",
        "    # If not, add samples from the training set to the test set\n",
        "    for missing_label in missing_labels:\n",
        "\n",
        "        # Collect the indices of the samples to be moved\n",
        "        missing_label_indices = y_train[y_train == missing_label].index.tolist()\n",
        "        # Get the index of the first occurence of the missing label\n",
        "        missing_label_index = missing_label_indices[0]\n",
        "\n",
        "        # Add these samples to the test set\n",
        "        X_test = pd.concat([X_test, X_train.loc[[missing_label_index]]], axis=0)\n",
        "        y_test = pd.concat([y_test, y_train.loc[[missing_label_index]]], axis=0)\n",
        "\n",
        "        # Remove these samples from the training set\n",
        "        X_train = X_train.drop(missing_label_index)\n",
        "        y_train = y_train.drop(missing_label_index)\n",
        "\n",
        "# Initialize the model\n",
        "bert_classifier = BertClassifier(training_args, id2label)\n",
        "\n",
        "# Load the weights of the model that achieve best metrics\n",
        "weights = torch.load(f'model/model_state_{run_number}.pt')\n",
        "bert_classifier.model.load_state_dict(weights)\n",
        "bert_classifier.model.eval() # Set model to evaluation mode\n",
        "\n",
        "# Make predictions\n",
        "pred_logits = bert_classifier.predict(X_test.to_list())\n",
        "y_pred = np.argmax(pred_logits, axis=1)\n",
        "\n",
        "# Get the classification report, rename the columns and save it to a CSV file\n",
        "_classification_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True, zero_division=0))\n",
        "\n",
        "_classification_report.to_csv(f'results/best_classification_report.csv', sep=';', index=False, encoding='utf-8')\n",
        "\n",
        "column_mapping = {str(old): str(old + 1) for old in range(0, 17)}\n",
        "_classification_report = _classification_report.rename(columns=column_mapping)\n",
        "_classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc999635",
      "metadata": {
        "id": "cc999635",
        "outputId": "2737fca2-f16a-482a-fe99-b41b764e7a92"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.999730</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000323</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.000386</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000416</td>\n",
              "      <td>0.000592</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>0.000338</td>\n",
              "      <td>0.000448</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>0.991174</td>\n",
              "      <td>0.002447</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.001349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000787</td>\n",
              "      <td>0.001338</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>0.000821</td>\n",
              "      <td>0.000901</td>\n",
              "      <td>0.001988</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>0.000939</td>\n",
              "      <td>0.000531</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>0.001052</td>\n",
              "      <td>0.001870</td>\n",
              "      <td>0.003058</td>\n",
              "      <td>0.953165</td>\n",
              "      <td>0.002166</td>\n",
              "      <td>0.027058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000766</td>\n",
              "      <td>0.005400</td>\n",
              "      <td>0.002651</td>\n",
              "      <td>0.000827</td>\n",
              "      <td>0.000885</td>\n",
              "      <td>0.939815</td>\n",
              "      <td>0.009679</td>\n",
              "      <td>0.000693</td>\n",
              "      <td>0.001023</td>\n",
              "      <td>0.000315</td>\n",
              "      <td>0.002198</td>\n",
              "      <td>0.001893</td>\n",
              "      <td>0.002914</td>\n",
              "      <td>0.002341</td>\n",
              "      <td>0.002761</td>\n",
              "      <td>0.001155</td>\n",
              "      <td>0.024684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.999503</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2754</th>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.999754</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2755</th>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.004973</td>\n",
              "      <td>0.098571</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.000376</td>\n",
              "      <td>0.000598</td>\n",
              "      <td>0.000562</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.000442</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>0.000881</td>\n",
              "      <td>0.000799</td>\n",
              "      <td>0.889569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2756</th>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000845</td>\n",
              "      <td>0.997743</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2757</th>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.999740</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2758</th>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.999730</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2759 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3         4         5         6   \\\n",
              "0     0.000008  0.000030  0.999730  0.000020  0.000019  0.000012  0.000028   \n",
              "1     0.000323  0.000123  0.000386  0.000213  0.000416  0.000592  0.000204   \n",
              "2     0.000787  0.001338  0.000390  0.000821  0.000901  0.001988  0.000723   \n",
              "3     0.000766  0.005400  0.002651  0.000827  0.000885  0.939815  0.009679   \n",
              "4     0.000012  0.000097  0.999503  0.000031  0.000026  0.000011  0.000045   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2754  0.000007  0.000029  0.999754  0.000016  0.000017  0.000012  0.000023   \n",
              "2755  0.000312  0.004973  0.098571  0.000439  0.000664  0.000249  0.000376   \n",
              "2756  0.000038  0.000845  0.997743  0.000081  0.000076  0.000023  0.000135   \n",
              "2757  0.000007  0.000035  0.999740  0.000015  0.000017  0.000010  0.000031   \n",
              "2758  0.000007  0.000033  0.999730  0.000016  0.000017  0.000010  0.000024   \n",
              "\n",
              "            7         8         9         10        11        12        13  \\\n",
              "0     0.000010  0.000014  0.000014  0.000011  0.000009  0.000004  0.000014   \n",
              "1     0.000390  0.000255  0.000458  0.000338  0.000448  0.000626  0.991174   \n",
              "2     0.000939  0.000531  0.000914  0.002300  0.001052  0.001870  0.003058   \n",
              "3     0.000693  0.001023  0.000315  0.002198  0.001893  0.002914  0.002341   \n",
              "4     0.000017  0.000020  0.000020  0.000014  0.000011  0.000005  0.000014   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2754  0.000009  0.000015  0.000012  0.000011  0.000009  0.000004  0.000014   \n",
              "2755  0.000598  0.000562  0.000664  0.000442  0.000257  0.000206  0.000438   \n",
              "2756  0.000060  0.000072  0.000071  0.000044  0.000036  0.000026  0.000043   \n",
              "2757  0.000010  0.000015  0.000012  0.000010  0.000009  0.000004  0.000014   \n",
              "2758  0.000010  0.000016  0.000012  0.000011  0.000009  0.000004  0.000014   \n",
              "\n",
              "            14        15        16  \n",
              "0     0.000006  0.000018  0.000053  \n",
              "1     0.002447  0.000258  0.001349  \n",
              "2     0.953165  0.002166  0.027058  \n",
              "3     0.002761  0.001155  0.024684  \n",
              "4     0.000010  0.000023  0.000141  \n",
              "...        ...       ...       ...  \n",
              "2754  0.000006  0.000016  0.000046  \n",
              "2755  0.000881  0.000799  0.889569  \n",
              "2756  0.000129  0.000076  0.000502  \n",
              "2757  0.000006  0.000015  0.000050  \n",
              "2758  0.000006  0.000017  0.000064  \n",
              "\n",
              "[2759 rows x 17 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply the softmax function to the prediction logits to get the probabilities\n",
        "prediction_probas = pd.DataFrame(pred_logits).apply(softmax, axis=1)\n",
        "prediction_probas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce7de30e",
      "metadata": {
        "id": "ce7de30e"
      },
      "outputs": [],
      "source": [
        "# This cell will filter the samples with a maximum predicted\n",
        "# probability below a certain threshold and create a new classification report\n",
        "\n",
        "# Ensure y_test and prediction_probas have the same indices\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "prediction_probas = prediction_probas.reset_index(drop=True)\n",
        "\n",
        "# Create a dataframe with the max probability value and the corresponding label\n",
        "max_values = pd.DataFrame({\n",
        "    'max_value': prediction_probas.max(axis=1), # maximum probabilities\n",
        "    'prediction': y_pred, # predictions\n",
        "})\n",
        "\n",
        "cap = 0.8\n",
        "number_max_value = len(max_values[max_values['max_value'] < cap])\n",
        "filtered_samples = max_values[max_values['max_value'] < cap]\n",
        "\n",
        "# Get the indices of the samples to exclude\n",
        "exclude_indices = filtered_samples.index\n",
        "predictions = pd.DataFrame(prediction_probas.values.argmax(axis=1))\n",
        "\n",
        "# Create new Series without the excluded samples\n",
        "filtered_pred = predictions.drop(exclude_indices)\n",
        "filtered_true = y_test.drop(exclude_indices)\n",
        "filtered_report = pd.DataFrame(classification_report(filtered_true, filtered_pred, output_dict=True, zero_division=0))\n",
        "\n",
        "# Create a mapping from old column names to new ones\n",
        "column_mapping = {str(old): str(old + 1) for old in range(0, 17)}\n",
        "\n",
        "# Rename the columns\n",
        "filtered_report.rename(columns=column_mapping, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3d1095e",
      "metadata": {
        "id": "e3d1095e",
        "outputId": "ff1be058-515d-4f8b-d021-8ffb5b11e18b",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.975974</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.915493</td>\n",
              "      <td>0.883019</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.810345</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.78125</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.876993</td>\n",
              "      <td>0.92556</td>\n",
              "      <td>0.541940</td>\n",
              "      <td>0.919562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.673077</td>\n",
              "      <td>0.981711</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.915493</td>\n",
              "      <td>0.924901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.78125</td>\n",
              "      <td>0.873418</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.873016</td>\n",
              "      <td>0.92556</td>\n",
              "      <td>0.533698</td>\n",
              "      <td>0.925560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.721649</td>\n",
              "      <td>0.978834</td>\n",
              "      <td>0.827586</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.915493</td>\n",
              "      <td>0.903475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.796610</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.78125</td>\n",
              "      <td>0.816568</td>\n",
              "      <td>0.792793</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.92556</td>\n",
              "      <td>0.537015</td>\n",
              "      <td>0.922270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>1.0</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>1531.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>32.00000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>441.000000</td>\n",
              "      <td>0.92556</td>\n",
              "      <td>2633.000000</td>\n",
              "      <td>2633.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             1          2            3          4    5          6           7  \\\n",
              "precision  0.0   0.777778     0.975974   0.857143  0.0   0.915493    0.883019   \n",
              "recall     0.0   0.673077     0.981711   0.800000  0.0   0.915493    0.924901   \n",
              "f1-score   0.0   0.721649     0.978834   0.827586  0.0   0.915493    0.903475   \n",
              "support    1.0  52.000000  1531.000000  15.000000  2.0  71.000000  253.000000   \n",
              "\n",
              "             8          9   10         11   12        13         14  \\\n",
              "precision  0.0   0.810345  0.0   0.782609  0.0   0.78125   0.766667   \n",
              "recall     0.0   0.783333  0.0   0.666667  0.0   0.78125   0.873418   \n",
              "f1-score   0.0   0.796610  0.0   0.720000  0.0   0.78125   0.816568   \n",
              "support    4.0  60.000000  2.0  27.000000  7.0  32.00000  79.000000   \n",
              "\n",
              "                  15   16          17  accuracy    macro avg  weighted avg  \n",
              "precision   0.785714  0.0    0.876993   0.92556     0.541940      0.919562  \n",
              "recall      0.800000  0.0    0.873016   0.92556     0.533698      0.925560  \n",
              "f1-score    0.792793  0.0    0.875000   0.92556     0.537015      0.922270  \n",
              "support    55.000000  1.0  441.000000   0.92556  2633.000000   2633.000000  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Classification report of samples with max probability over 80%\n",
        "filtered_report.to_csv('results/best_classification_report_80.csv', sep=';', index=False, encoding='utf-8')\n",
        "filtered_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bc1fc91",
      "metadata": {
        "id": "0bc1fc91"
      },
      "outputs": [],
      "source": [
        "# Predictions where if the maximum predicted probability is 80% or more the prediction is set to corresponding SDG,\n",
        "# otherwise it is considered as unrelated and set to 0\n",
        "predictions_80 = prediction_probas.idxmax(axis=1).where(prediction_probas.max(axis=1) >= 0.8, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d88754b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "a0837de7",
        "02ffcd69",
        "Mw0oazPkrgOJ",
        "5b55cde2"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
